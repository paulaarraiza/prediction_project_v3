{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "940889cf-06e0-4e8c-8efa-1eeacc97ca57",
   "metadata": {},
   "source": [
    "## **This notebook aims to compare some models and store them in a reasonable fashion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e46c228-21f4-4e80-a4e8-b62981ab4799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a11a538-40d5-49c3-92e9-e26fdcefe083",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Use GPU 0 in first notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b259658-5fed-4231-9f06-f9db567e1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"/home/jupyter-tfg2425paula/prediction_project_v3\"\n",
    "os.chdir(project_dir)\n",
    "\n",
    "clean_data_dir = os.path.join(project_dir, \"00_data/clean\")\n",
    "horizontal_data_dir = os.path.join(project_dir, \"00_data/horizontal_structure\")\n",
    "results_dir = os.path.join(project_dir, \"02_results\")\n",
    "plots_dir = os.path.join(project_dir, \"03_plots\")\n",
    "pca_data_dir = os.path.join(project_dir, \"00_data/pca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7319029-ba4c-4c90-91b9-a0a02b5be9af",
   "metadata": {},
   "source": [
    "### **GRU Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a1485d-99bb-4358-a216-1c1c75e50ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU3DClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, dropout):\n",
    "        super(GRU3DClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # return self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3061a6b4-dad3-4129-a2ed-0098e04440e4",
   "metadata": {},
   "source": [
    "### **LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95ffa6e2-2c35-48de-8c95-b7ce86fe9dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockPriceLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1, dropout=0.0):\n",
    "        super(StockPriceLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, \n",
    "                            batch_first=True, dropout=dropout)\n",
    "    \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)  # Get the batch size dynamically\n",
    "\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)  # (num_layers, batch_size, hidden_dim)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(x.device)  # (num_layers, batch_size, hidden_dim)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        # out = self.sigmoid(out)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6d4b78-1492-45ea-a9af-854d8d69b8de",
   "metadata": {},
   "source": [
    "### **Set folders**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67b679f-204f-4e15-89fe-09879ed7246c",
   "metadata": {},
   "source": [
    "Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b80ed82-98cd-453d-94e9-b7f42c61040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_types = [\"clean\", \"pca\"]\n",
    "processing_types= [\"clean\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3781cf-0f0b-4858-bff8-09f839e2da04",
   "metadata": {},
   "source": [
    "Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2958856-f0de-4f93-85b5-9fdd169a2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stocks = ['AAPL', 'MSFT', 'AMZN', 'NVDA', 'SPX']\n",
    "stocks = ['AAPL']\n",
    "# types_securities = [\"single_name\", \"options\", \"technical\"]\n",
    "types_securities = [\"single_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e929df-0399-4e41-9b2b-1863f8c215b5",
   "metadata": {},
   "source": [
    "Different files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b853df6-38b4-4bd7-85e5-6a232f17905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# years = [\"15y\", \"10y\", \"5y\", \"2y\"]\n",
    "years = [\"10y\"]\n",
    "# window_sizes = [5, 10, 50, 100]\n",
    "window_sizes = [5]\n",
    "# train_sizes = [80, 90, 95]\n",
    "train_sizes = [95]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9fb2cc-d8de-4e4f-be9d-f8cb7aac8e16",
   "metadata": {},
   "source": [
    "Same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "145e5ba2-35c7-4a71-b100-624ca6ed1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "thresholds = [0.5]\n",
    "learning_rates = [0.005, 0.008, 0.009, 0.01]\n",
    "learning_rates = [0.01]\n",
    "num_epochs_list = [100, 200]\n",
    "num_epochs_list = [100]\n",
    "batch_sizes = [16, 32]\n",
    "batch_sizes = [32]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbee35f-0147-48b0-93ef-d9687984bbd0",
   "metadata": {},
   "source": [
    "#### **Model and Hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71861bc1-7067-47f8-b3dd-a5cef2bc0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "hidden_size = 64  \n",
    "output_size = 2  \n",
    "num_layers = 2\n",
    "dropout = 0.2\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60900dea-a72e-4b53-979b-aded1e725489",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [\"lstm\", \"gru\"]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d873f70-b583-4e84-9289-bc303ef0446f",
   "metadata": {},
   "source": [
    "#### **Last data modifications**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85729e3c-f060-4dc2-a4fc-a80573fefd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_remove_characters(df):\n",
    "\n",
    "    X = np.array([np.stack(row) for row in df.drop(columns=['Target']).values])\n",
    "    y = df['Target'].values\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    n_samples, timesteps, n_features = X.shape\n",
    "    X_flat = X.reshape((n_samples, timesteps * n_features))\n",
    "    X_flat = np.where(X_flat == 'ç', 0, X_flat)\n",
    "\n",
    "    X_resampled = X_flat.reshape((-1, timesteps, n_features))\n",
    "    \n",
    "    return X_resampled, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88656719-d0c4-4bf2-aef1-31f00b167d2a",
   "metadata": {},
   "source": [
    "### **Evaluation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8953eb19-f0c8-4c66-bdfa-9bd8a8a92b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model_plot(\n",
    "    model, \n",
    "    X, \n",
    "    y, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    device, \n",
    "    train_size, \n",
    "    batch_size, \n",
    "    num_epochs, \n",
    "    lower_threshold,\n",
    "    plots_dir=None,\n",
    "    plot_filename=None\n",
    "):\n",
    "\n",
    "    # -------------------------------\n",
    "    # 0) Prepare Tensors & Splits\n",
    "    # -------------------------------\n",
    "    X = torch.tensor(X, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "    total_size = len(X)\n",
    "    # Determine actual train_size index\n",
    "    if train_size < 1.0:\n",
    "        lower_bound = int(train_size * total_size)\n",
    "    else:\n",
    "        lower_bound = train_size\n",
    "\n",
    "    # Training portion\n",
    "    X_train = X[:lower_bound].to(device)\n",
    "    y_train = y[:lower_bound].to(device)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    trainloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,   # Set True if you prefer shuffling\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    if lower_bound < total_size:\n",
    "        X_val = X[lower_bound:].to(device)\n",
    "        y_val = y[lower_bound:].to(device)\n",
    "        val_dataset = TensorDataset(X_val, y_val)\n",
    "        valloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    else:\n",
    "        # If there's no leftover data for \"test\", handle gracefully\n",
    "        X_val = None\n",
    "        y_val = None\n",
    "        valloader = None\n",
    "\n",
    "    # ---------------------------------------------\n",
    "    # 1) SINGLE TRAINING PHASE + Track Loss Curves\n",
    "    # ---------------------------------------------\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    epoch_train_losses = []\n",
    "    epoch_test_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # TRAINING PASS\n",
    "        epoch_loss = 0.0\n",
    "        for X_batch, y_batch in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            pred_y = model(X_batch)\n",
    "            loss = criterion(pred_y, y_batch)\n",
    "\n",
    "            # Backprop & update\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # optional\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = epoch_loss / len(trainloader)\n",
    "        epoch_train_losses.append(avg_train_loss)\n",
    "\n",
    "        # VALIDATION PASS (Optional but needed to get test_loss_curve)\n",
    "        if valloader is not None:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for Xb, yb in valloader:\n",
    "                    pred_yb = model(Xb)\n",
    "                    loss_b = criterion(pred_yb, yb)\n",
    "                    val_loss += loss_b.item()\n",
    "            avg_val_loss = val_loss / len(valloader)\n",
    "            epoch_test_losses.append(avg_val_loss)\n",
    "\n",
    "            model.train()  # Switch back to train mode\n",
    "\n",
    "        else:\n",
    "            # If no validation set, just store None or 0\n",
    "            epoch_test_losses.append(None)\n",
    "\n",
    "        # Print progress every 5 epochs or last epoch\n",
    "        if (epoch + 1) % 5 == 0 or (epoch == num_epochs - 1):\n",
    "            if epoch_test_losses[-1] is not None:\n",
    "                print(f\"[Epoch {epoch+1}/{num_epochs}] \"\n",
    "                      f\"Train Loss: {avg_train_loss:.4f}, \"\n",
    "                      f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "            else:\n",
    "                print(f\"[Epoch {epoch+1}/{num_epochs}] \"\n",
    "                      f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # % decrease from first to last train loss\n",
    "    if len(epoch_train_losses) > 1:\n",
    "        loss_decrease_percentage = ((epoch_train_losses[-1] - epoch_train_losses[0])\n",
    "                                    / epoch_train_losses[0]) * 100\n",
    "    else:\n",
    "        loss_decrease_percentage = 0.0\n",
    "\n",
    "    final_train_loss = epoch_train_losses[-1]\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2) ROLLING PREDICTIONS, NO UPDATE\n",
    "    # -------------------------------\n",
    "    model.eval()\n",
    "    rolling_predictions = []\n",
    "    rolling_targets = []\n",
    "\n",
    "    for i in range(lower_bound, total_size):\n",
    "        X_test = X[i:i+1].to(device)\n",
    "        y_test = y[i:i+1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_y = model(X_test)\n",
    "            probabilities = torch.softmax(pred_y, dim=1).cpu().numpy()\n",
    "            prob_class_1 = probabilities[:, 1]  # shape: (1,)\n",
    "\n",
    "            # Threshold-based logic\n",
    "            pred_classes = np.zeros_like(prob_class_1)\n",
    "            # Predict -1 if prob < lower_threshold\n",
    "            pred_classes[prob_class_1 < lower_threshold] = -1\n",
    "            # Predict +1 if prob > (1 - lower_threshold)\n",
    "            pred_classes[prob_class_1 > (1 - lower_threshold)] = 1\n",
    "\n",
    "        rolling_predictions.append(pred_classes[0])\n",
    "        rolling_targets.append(y_test.item())\n",
    "\n",
    "    rolling_predictions = np.array(rolling_predictions)\n",
    "    rolling_targets = np.array(rolling_targets).astype(int)\n",
    "\n",
    "    # If original labels might be {0,1}, adapt as needed\n",
    "    rolling_targets[rolling_targets == 0] = -1\n",
    "\n",
    "    # Filter out zero predictions\n",
    "    nonzero_mask = (rolling_predictions != 0)\n",
    "    filtered_preds = rolling_predictions[nonzero_mask]\n",
    "    filtered_targets = rolling_targets[nonzero_mask]\n",
    "\n",
    "    if len(filtered_preds) == 0:\n",
    "        accuracy_nonzero = None\n",
    "        print(\"No nonzero predictions, cannot compute thresholded accuracy.\")\n",
    "    else:\n",
    "        accuracy_nonzero = accuracy_score(filtered_targets, filtered_preds)\n",
    "        print(f\"Accuracy on Nonzero Predictions: {accuracy_nonzero:.4f}\")\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # 3) PLOT (if plots_dir is set and there's test data)\n",
    "    # -------------------------------------------------\n",
    "    if plots_dir is not None:\n",
    "        os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "        # If user didn't provide a filename, create a default\n",
    "        if plot_filename is None:\n",
    "            plot_filename = \"train_test_loss_curve.png\"\n",
    "        plot_path = os.path.join(plots_dir, plot_filename)\n",
    "\n",
    "        # Plot the training and validation (test) loss curves\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(epoch_train_losses, label=\"Train Loss\")\n",
    "        # Only plot test loss if it isn't None\n",
    "        if any(x is not None for x in epoch_test_losses):\n",
    "            plt.plot(epoch_test_losses, label=\"Test Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Train vs. Test Loss per Epoch\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Loss curves saved to: {plot_path}\")\n",
    "\n",
    "    # ----------------\n",
    "    # 4) Return results\n",
    "    # ----------------\n",
    "    return {\n",
    "        \"rolling_predictions\": rolling_predictions,\n",
    "        \"rolling_targets\": rolling_targets,\n",
    "        \"filtered_predictions\": filtered_preds,\n",
    "        \"filtered_targets\": filtered_targets,\n",
    "        \"accuracy_nonzero\": accuracy_nonzero,\n",
    "        \"loss_decrease_percentage\": loss_decrease_percentage,\n",
    "        \"final_train_loss\": final_train_loss,\n",
    "        \"train_loss_curve\": epoch_train_losses,\n",
    "        \"test_loss_curve\": epoch_test_losses\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6ada8-f935-4595-afa1-cfbfe990b5fd",
   "metadata": {},
   "source": [
    "### **Execute evaluation funcion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "152fb8d5-715f-4409-8b9f-8b01040b777b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- LEARNING_RATE: 0.01, SECURITY_TYPE: single_name, MODEL_TYPE: lstm -----\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Security type: single_name\n",
      "[Epoch 5/100] Train Loss: 0.6937, Val Loss: 0.6912\n",
      "[Epoch 10/100] Train Loss: 0.6933, Val Loss: 0.6914\n",
      "[Epoch 15/100] Train Loss: 0.6929, Val Loss: 0.6922\n",
      "[Epoch 20/100] Train Loss: 0.6926, Val Loss: 0.6916\n",
      "[Epoch 25/100] Train Loss: 0.6919, Val Loss: 0.6905\n",
      "[Epoch 30/100] Train Loss: 0.6912, Val Loss: 0.6895\n",
      "[Epoch 35/100] Train Loss: 0.6907, Val Loss: 0.6885\n",
      "[Epoch 40/100] Train Loss: 0.6904, Val Loss: 0.6877\n",
      "[Epoch 45/100] Train Loss: 0.6901, Val Loss: 0.6870\n",
      "[Epoch 50/100] Train Loss: 0.6896, Val Loss: 0.6863\n",
      "[Epoch 55/100] Train Loss: 0.6890, Val Loss: 0.6856\n",
      "[Epoch 60/100] Train Loss: 0.6884, Val Loss: 0.6841\n",
      "[Epoch 65/100] Train Loss: 0.6877, Val Loss: 0.6821\n",
      "[Epoch 70/100] Train Loss: 0.6869, Val Loss: 0.6809\n",
      "[Epoch 75/100] Train Loss: 0.6861, Val Loss: 0.6795\n",
      "[Epoch 80/100] Train Loss: 0.6855, Val Loss: 0.6785\n",
      "[Epoch 85/100] Train Loss: 0.6849, Val Loss: 0.6775\n",
      "[Epoch 90/100] Train Loss: 0.6841, Val Loss: 0.6768\n",
      "[Epoch 95/100] Train Loss: 0.6836, Val Loss: 0.6773\n",
      "[Epoch 100/100] Train Loss: 0.6829, Val Loss: 0.6775\n",
      "Accuracy on Nonzero Predictions: 0.5725\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "stock = \"AAPL\"\n",
    "period = \"10y\"\n",
    "possible_train_size = 95\n",
    "window_size = 5\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "window_size = 3\n",
    "prediction_threshold = 0.5\n",
    "\n",
    "processing = \"clean\"\n",
    "security_types = [\"single_name\"]\n",
    "learning_rate = 0.01\n",
    "model_type = \"lstm\"\n",
    "\n",
    "results_list = []\n",
    "for security_type in security_types:\n",
    "    initial_data_dir = os.path.join(project_dir, f\"00_data/{processing}\") \n",
    "    \n",
    "    # 1) Load original data (info only)\n",
    "    filename = f\"{security_type}/{stock}/{period}_data.csv\"\n",
    "    original_input_filepath = os.path.join(initial_data_dir, filename)\n",
    "    original_data = pd.read_csv(original_input_filepath)\n",
    "\n",
    "    print(f\"\\n----- LEARNING_RATE: {learning_rate}, SECURITY_TYPE: {security_type}, MODEL_TYPE: {model_type} -----\")\n",
    "\n",
    "    # 2) Load the preprocessed data\n",
    "    pkl_filename = f\"{processing}/{security_type}/{stock}/{period}_{window_size}_data.pkl\"\n",
    "    input_filepath = os.path.join(horizontal_data_dir, pkl_filename)\n",
    "    input_df = pd.read_pickle(input_filepath)\n",
    "    \n",
    "    # 3) Reshape\n",
    "    X_resampled, y_resampled = reshape_remove_characters(input_df)\n",
    "\n",
    "    input_size = X_resampled.shape[2]\n",
    "    train_size = int(X_resampled.shape[0] * possible_train_size / 100)\n",
    "    test_size = X_resampled.shape[0] - train_size\n",
    "\n",
    "        \n",
    "     # for model_type in model_types:\n",
    "            # 4) Initialize the model\n",
    "    if model_type == \"gru\":\n",
    "        model = GRU3DClassifier(input_size, hidden_size, output_size, num_layers, dropout)\n",
    "    elif model_type == \"lstm\":\n",
    "        model = StockPriceLSTM(input_size, hidden_size, output_size)\n",
    "    \n",
    "    model = model.to(device)\n",
    "\n",
    "    # 5) Set up optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    print(f\"Training {stock} | LR: {learning_rate} | Epochs: {num_epochs} \"\n",
    "          f\"| Batch: {batch_size} | Security type: {security_type}\")\n",
    "\n",
    "    result = evaluate_model_plot(\n",
    "        model=model,\n",
    "        X=X_resampled,\n",
    "        y=y_resampled,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "        train_size=train_size,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=num_epochs,\n",
    "        lower_threshold=0.5,\n",
    "        plots_dir=plots_dir,                # folder where plots are saved\n",
    "        plot_filename=f\"learning_rates/AAPL_{model_type}_lr{learning_rate}_{security_type}.png\" # optional custom filename\n",
    "    )\n",
    "\n",
    "    # 7) Extract results\n",
    "    rolling_predictions = result[\"rolling_predictions\"]\n",
    "    rolling_targets = result[\"rolling_targets\"]\n",
    "    test_accuracy = result[\"accuracy_nonzero\"]\n",
    "    loss_decrease_percentage = result[\"loss_decrease_percentage\"]\n",
    "    nonzero_preds = np.count_nonzero(rolling_predictions)\n",
    "    final_train_loss = result[\"final_train_loss\"]\n",
    "\n",
    "    # 9) Create a record (dictionary) for this run\n",
    "    run_record = {\n",
    "        \"STOCK\": stock,\n",
    "        \"DATA_TYPE\": security_type,\n",
    "        \"MODEL\": model_type.upper(),\n",
    "        \"PROCESSING\": processing,\n",
    "        \"ACCURACY\": test_accuracy,\n",
    "        \"TRAIN_PCT_DECREASE\": loss_decrease_percentage,\n",
    "        \"FINAL_TRAIN_LOSS\": final_train_loss\n",
    "    }\n",
    "\n",
    "    # 10) Append to the results_list\n",
    "    results_list.append(run_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06957e37-5441-4298-b426-26ac951037ed",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean, lstm, single_name\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/horizontal_structure/clean/single_name/AAPL/10y_5_data.pkl\n",
      "Training AAPL | LR: 0.009 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6930, Val Loss: 0.6921\n",
      "[Epoch 10/100] Train Loss: 0.6906, Val Loss: 0.6914\n",
      "[Epoch 15/100] Train Loss: 0.6891, Val Loss: 0.6899\n",
      "[Epoch 20/100] Train Loss: 0.6877, Val Loss: 0.6884\n",
      "[Epoch 25/100] Train Loss: 0.6834, Val Loss: 0.6842\n",
      "[Epoch 30/100] Train Loss: 0.6787, Val Loss: 0.6837\n",
      "[Epoch 35/100] Train Loss: 0.6741, Val Loss: 0.6843\n",
      "[Epoch 40/100] Train Loss: 0.6698, Val Loss: 0.6824\n",
      "[Epoch 45/100] Train Loss: 0.6653, Val Loss: 0.6824\n",
      "[Epoch 50/100] Train Loss: 0.6610, Val Loss: 0.6849\n",
      "[Epoch 55/100] Train Loss: 0.6564, Val Loss: 0.6819\n",
      "[Epoch 60/100] Train Loss: 0.6485, Val Loss: 0.6795\n",
      "[Epoch 65/100] Train Loss: 0.6427, Val Loss: 0.6814\n",
      "[Epoch 70/100] Train Loss: 0.6374, Val Loss: 0.6828\n",
      "[Epoch 75/100] Train Loss: 0.6312, Val Loss: 0.6884\n",
      "[Epoch 80/100] Train Loss: 0.6261, Val Loss: 0.6923\n",
      "[Epoch 85/100] Train Loss: 0.6209, Val Loss: 0.6954\n",
      "[Epoch 90/100] Train Loss: 0.6156, Val Loss: 0.6995\n",
      "[Epoch 95/100] Train Loss: 0.6105, Val Loss: 0.7045\n",
      "[Epoch 100/100] Train Loss: 0.6046, Val Loss: 0.7098\n",
      "Accuracy on Nonzero Predictions: 0.5649\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_lstm_lr0.009_single_name.png\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.5992, Val Loss: 0.7161\n",
      "[Epoch 10/100] Train Loss: 0.5947, Val Loss: 0.7253\n",
      "[Epoch 15/100] Train Loss: 0.5898, Val Loss: 0.7406\n",
      "[Epoch 20/100] Train Loss: 0.5846, Val Loss: 0.7599\n",
      "[Epoch 25/100] Train Loss: 0.5798, Val Loss: 0.7724\n",
      "[Epoch 30/100] Train Loss: 0.5749, Val Loss: 0.7818\n",
      "[Epoch 35/100] Train Loss: 0.5698, Val Loss: 0.7871\n",
      "[Epoch 40/100] Train Loss: 0.5651, Val Loss: 0.7936\n",
      "[Epoch 45/100] Train Loss: 0.5600, Val Loss: 0.7952\n",
      "[Epoch 50/100] Train Loss: 0.5556, Val Loss: 0.8008\n",
      "[Epoch 55/100] Train Loss: 0.5507, Val Loss: 0.8048\n",
      "[Epoch 60/100] Train Loss: 0.5468, Val Loss: 0.8146\n",
      "[Epoch 65/100] Train Loss: 0.5423, Val Loss: 0.8233\n",
      "[Epoch 70/100] Train Loss: 0.5383, Val Loss: 0.8328\n",
      "[Epoch 75/100] Train Loss: 0.5335, Val Loss: 0.8377\n",
      "[Epoch 80/100] Train Loss: 0.5299, Val Loss: 0.8440\n",
      "[Epoch 85/100] Train Loss: 0.5265, Val Loss: 0.8509\n",
      "[Epoch 90/100] Train Loss: 0.5231, Val Loss: 0.8578\n",
      "[Epoch 95/100] Train Loss: 0.5204, Val Loss: 0.8679\n",
      "[Epoch 100/100] Train Loss: 0.5173, Val Loss: 0.8768\n",
      "Accuracy on Nonzero Predictions: 0.5649\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_lstm_lr0.01_single_name.png\n",
      "Training AAPL | LR: 0.011 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.5156, Val Loss: 0.8804\n",
      "[Epoch 10/100] Train Loss: 0.5123, Val Loss: 0.8940\n",
      "[Epoch 15/100] Train Loss: 0.5092, Val Loss: 0.8995\n",
      "[Epoch 20/100] Train Loss: 0.5065, Val Loss: 0.9063\n",
      "[Epoch 25/100] Train Loss: 0.5035, Val Loss: 0.9152\n",
      "[Epoch 30/100] Train Loss: 0.5011, Val Loss: 0.9205\n",
      "[Epoch 35/100] Train Loss: 0.5042, Val Loss: 0.9341\n",
      "[Epoch 40/100] Train Loss: 0.4954, Val Loss: 0.9414\n",
      "[Epoch 45/100] Train Loss: 0.4903, Val Loss: 0.9544\n",
      "[Epoch 50/100] Train Loss: 0.4876, Val Loss: 0.9663\n",
      "[Epoch 55/100] Train Loss: 0.4843, Val Loss: 0.9768\n",
      "[Epoch 60/100] Train Loss: 0.4807, Val Loss: 0.9886\n",
      "[Epoch 65/100] Train Loss: 0.4782, Val Loss: 0.9959\n",
      "[Epoch 70/100] Train Loss: 0.4716, Val Loss: 1.0230\n",
      "[Epoch 75/100] Train Loss: 0.4656, Val Loss: 1.0444\n",
      "[Epoch 80/100] Train Loss: 0.4620, Val Loss: 1.0541\n",
      "[Epoch 85/100] Train Loss: 0.4587, Val Loss: 1.0688\n",
      "[Epoch 90/100] Train Loss: 0.4579, Val Loss: 1.0719\n",
      "[Epoch 95/100] Train Loss: 0.4513, Val Loss: 1.0740\n",
      "[Epoch 100/100] Train Loss: 0.4416, Val Loss: 1.1003\n",
      "Accuracy on Nonzero Predictions: 0.5802\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_lstm_lr0.011_single_name.png\n",
      "[0.5648854961832062, 0.5648854961832062, 0.5801526717557252]\n",
      "[-13.069365985654535, -14.765485336143753, -15.603392415675913]\n",
      "pca, lstm, technical\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/horizontal_structure/pca/technical/AAPL/10y_5_data.pkl\n",
      "Training AAPL | LR: 0.009 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6999, Val Loss: 0.6868\n",
      "[Epoch 10/100] Train Loss: 0.6962, Val Loss: 0.6857\n",
      "[Epoch 15/100] Train Loss: 0.6918, Val Loss: 0.7085\n",
      "[Epoch 20/100] Train Loss: 0.6877, Val Loss: 0.7045\n",
      "[Epoch 25/100] Train Loss: 0.6823, Val Loss: 0.7367\n",
      "[Epoch 30/100] Train Loss: 0.6692, Val Loss: 0.7354\n",
      "[Epoch 35/100] Train Loss: 0.6688, Val Loss: 0.7675\n",
      "[Epoch 40/100] Train Loss: 0.6391, Val Loss: 0.7243\n",
      "[Epoch 45/100] Train Loss: 0.6177, Val Loss: 0.7848\n",
      "[Epoch 50/100] Train Loss: 0.5899, Val Loss: 0.7467\n",
      "[Epoch 55/100] Train Loss: 0.5407, Val Loss: 0.8779\n",
      "[Epoch 60/100] Train Loss: 0.5179, Val Loss: 0.9509\n",
      "[Epoch 65/100] Train Loss: 0.4759, Val Loss: 0.9219\n",
      "[Epoch 70/100] Train Loss: 0.3978, Val Loss: 1.0941\n",
      "[Epoch 75/100] Train Loss: 0.3709, Val Loss: 1.1382\n",
      "[Epoch 80/100] Train Loss: 0.3173, Val Loss: 1.2774\n",
      "[Epoch 85/100] Train Loss: 0.2839, Val Loss: 1.4042\n",
      "[Epoch 90/100] Train Loss: 0.3072, Val Loss: 1.4872\n",
      "[Epoch 95/100] Train Loss: 0.2492, Val Loss: 1.5272\n",
      "[Epoch 100/100] Train Loss: 0.2199, Val Loss: 1.9120\n",
      "Accuracy on Nonzero Predictions: 0.5476\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_pca_lstm_lr0.009_technical.png\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.2568, Val Loss: 1.9225\n",
      "[Epoch 10/100] Train Loss: 0.2186, Val Loss: 1.8327\n",
      "[Epoch 15/100] Train Loss: 0.1990, Val Loss: 2.0801\n",
      "[Epoch 20/100] Train Loss: 0.1804, Val Loss: 1.8781\n",
      "[Epoch 25/100] Train Loss: 0.1749, Val Loss: 2.0780\n",
      "[Epoch 30/100] Train Loss: 0.1371, Val Loss: 1.9629\n",
      "[Epoch 35/100] Train Loss: 0.1406, Val Loss: 2.2323\n",
      "[Epoch 40/100] Train Loss: 0.1650, Val Loss: 2.3222\n",
      "[Epoch 45/100] Train Loss: 0.1535, Val Loss: 2.3666\n",
      "[Epoch 50/100] Train Loss: 0.1427, Val Loss: 2.0980\n",
      "[Epoch 55/100] Train Loss: 0.1019, Val Loss: 2.0707\n",
      "[Epoch 60/100] Train Loss: 0.1481, Val Loss: 2.1499\n",
      "[Epoch 65/100] Train Loss: 0.1242, Val Loss: 2.0861\n",
      "[Epoch 70/100] Train Loss: 0.1015, Val Loss: 2.4635\n",
      "[Epoch 75/100] Train Loss: 0.0979, Val Loss: 2.2812\n",
      "[Epoch 80/100] Train Loss: 0.1628, Val Loss: 2.3897\n",
      "[Epoch 85/100] Train Loss: 0.1106, Val Loss: 2.2857\n",
      "[Epoch 90/100] Train Loss: 0.1177, Val Loss: 2.2392\n",
      "[Epoch 95/100] Train Loss: 0.0932, Val Loss: 2.4349\n",
      "[Epoch 100/100] Train Loss: 0.1002, Val Loss: 2.6925\n",
      "Accuracy on Nonzero Predictions: 0.5079\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_pca_lstm_lr0.01_technical.png\n",
      "Training AAPL | LR: 0.011 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.2108, Val Loss: 2.5511\n",
      "[Epoch 10/100] Train Loss: 0.1205, Val Loss: 2.6782\n",
      "[Epoch 15/100] Train Loss: 0.1063, Val Loss: 2.4212\n",
      "[Epoch 20/100] Train Loss: 0.1486, Val Loss: 2.3381\n",
      "[Epoch 25/100] Train Loss: 0.1308, Val Loss: 2.5008\n",
      "[Epoch 30/100] Train Loss: 0.2009, Val Loss: 2.4381\n",
      "[Epoch 35/100] Train Loss: 0.1652, Val Loss: 2.4034\n",
      "[Epoch 40/100] Train Loss: 0.1644, Val Loss: 2.6246\n",
      "[Epoch 45/100] Train Loss: 0.1046, Val Loss: 2.5954\n",
      "[Epoch 50/100] Train Loss: 0.0970, Val Loss: 2.4391\n",
      "[Epoch 55/100] Train Loss: 0.0780, Val Loss: 2.6598\n",
      "[Epoch 60/100] Train Loss: 0.0906, Val Loss: 2.6200\n",
      "[Epoch 65/100] Train Loss: 0.0673, Val Loss: 2.6574\n",
      "[Epoch 70/100] Train Loss: 0.1190, Val Loss: 2.7683\n",
      "[Epoch 75/100] Train Loss: 0.1445, Val Loss: 2.1823\n",
      "[Epoch 80/100] Train Loss: 0.1356, Val Loss: 2.2268\n",
      "[Epoch 85/100] Train Loss: 0.1165, Val Loss: 2.3485\n",
      "[Epoch 90/100] Train Loss: 0.1438, Val Loss: 2.6897\n",
      "[Epoch 95/100] Train Loss: 0.1059, Val Loss: 2.6577\n",
      "[Epoch 100/100] Train Loss: 0.1177, Val Loss: 2.4246\n",
      "Accuracy on Nonzero Predictions: 0.5476\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_pca_lstm_lr0.011_technical.png\n",
      "[0.5476190476190477, 0.5079365079365079, 0.5476190476190477]\n",
      "[-68.3226634481063, -58.987081993439304, -10.680032205145197]\n",
      "pca, lstm, options\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/horizontal_structure/pca/options/AAPL/10y_5_data.pkl\n",
      "Training AAPL | LR: 0.009 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6936, Val Loss: 0.6901\n",
      "[Epoch 10/100] Train Loss: 0.6920, Val Loss: 0.6986\n",
      "[Epoch 15/100] Train Loss: 0.6455, Val Loss: 0.7294\n",
      "[Epoch 20/100] Train Loss: 0.5396, Val Loss: 0.8689\n",
      "[Epoch 25/100] Train Loss: 0.3858, Val Loss: 0.9710\n",
      "[Epoch 30/100] Train Loss: 0.2470, Val Loss: 1.3581\n",
      "[Epoch 35/100] Train Loss: 0.1622, Val Loss: 1.5220\n",
      "[Epoch 40/100] Train Loss: 0.0668, Val Loss: 1.5964\n",
      "[Epoch 45/100] Train Loss: 0.0565, Val Loss: 1.9551\n",
      "[Epoch 50/100] Train Loss: 0.0213, Val Loss: 2.0190\n",
      "[Epoch 55/100] Train Loss: 0.0674, Val Loss: 2.2453\n",
      "[Epoch 60/100] Train Loss: 0.0543, Val Loss: 2.0694\n",
      "[Epoch 65/100] Train Loss: 0.0200, Val Loss: 1.9258\n",
      "[Epoch 70/100] Train Loss: 0.0132, Val Loss: 2.0132\n",
      "[Epoch 75/100] Train Loss: 0.0250, Val Loss: 2.4856\n",
      "[Epoch 80/100] Train Loss: 0.0616, Val Loss: 2.3172\n",
      "[Epoch 85/100] Train Loss: 0.0038, Val Loss: 2.1481\n",
      "[Epoch 90/100] Train Loss: 0.0041, Val Loss: 2.1095\n",
      "[Epoch 95/100] Train Loss: 0.0010, Val Loss: 2.4409\n",
      "[Epoch 100/100] Train Loss: 0.0003, Val Loss: 2.4514\n",
      "Accuracy on Nonzero Predictions: 0.5573\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_pca_lstm_lr0.009_options.png\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.0480, Val Loss: 2.4426\n",
      "[Epoch 10/100] Train Loss: 0.0108, Val Loss: 2.6244\n",
      "[Epoch 15/100] Train Loss: 0.0013, Val Loss: 2.7146\n",
      "[Epoch 20/100] Train Loss: 0.0002, Val Loss: 2.6467\n",
      "[Epoch 25/100] Train Loss: 0.0001, Val Loss: 2.6667\n",
      "[Epoch 30/100] Train Loss: 0.0001, Val Loss: 2.6924\n",
      "[Epoch 35/100] Train Loss: 0.0001, Val Loss: 2.7194\n",
      "[Epoch 40/100] Train Loss: 0.0001, Val Loss: 2.7474\n",
      "[Epoch 45/100] Train Loss: 0.0000, Val Loss: 2.7763\n",
      "[Epoch 50/100] Train Loss: 0.0000, Val Loss: 2.8064\n",
      "[Epoch 55/100] Train Loss: 0.0000, Val Loss: 2.8378\n",
      "[Epoch 60/100] Train Loss: 0.0000, Val Loss: 2.8703\n",
      "[Epoch 65/100] Train Loss: 0.0000, Val Loss: 2.9041\n",
      "[Epoch 70/100] Train Loss: 0.0000, Val Loss: 2.9390\n",
      "[Epoch 75/100] Train Loss: 0.0000, Val Loss: 2.9749\n",
      "[Epoch 80/100] Train Loss: 0.0000, Val Loss: 3.0118\n",
      "[Epoch 85/100] Train Loss: 0.0000, Val Loss: 3.0495\n",
      "[Epoch 90/100] Train Loss: 0.0000, Val Loss: 3.0880\n",
      "[Epoch 95/100] Train Loss: 0.0000, Val Loss: 3.1272\n",
      "[Epoch 100/100] Train Loss: 0.0000, Val Loss: 3.1670\n",
      "Accuracy on Nonzero Predictions: 0.5038\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_pca_lstm_lr0.01_options.png\n",
      "Training AAPL | LR: 0.011 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.0619, Val Loss: 2.6138\n",
      "[Epoch 10/100] Train Loss: 0.0405, Val Loss: 2.5910\n",
      "[Epoch 15/100] Train Loss: 0.0512, Val Loss: 2.8485\n",
      "[Epoch 20/100] Train Loss: 0.0166, Val Loss: 3.0525\n",
      "[Epoch 25/100] Train Loss: 0.0236, Val Loss: 3.1428\n",
      "[Epoch 30/100] Train Loss: 0.0197, Val Loss: 3.7901\n",
      "[Epoch 35/100] Train Loss: 0.0357, Val Loss: 3.5215\n",
      "[Epoch 40/100] Train Loss: 0.0086, Val Loss: 2.8031\n",
      "[Epoch 45/100] Train Loss: 0.1261, Val Loss: 3.4015\n",
      "[Epoch 50/100] Train Loss: 0.0407, Val Loss: 3.4930\n",
      "[Epoch 55/100] Train Loss: 0.0129, Val Loss: 3.6761\n",
      "[Epoch 60/100] Train Loss: 0.0030, Val Loss: 3.6005\n",
      "[Epoch 65/100] Train Loss: 0.0039, Val Loss: 3.9924\n",
      "[Epoch 70/100] Train Loss: 0.0572, Val Loss: 4.1896\n",
      "[Epoch 75/100] Train Loss: 0.0476, Val Loss: 3.7026\n",
      "[Epoch 80/100] Train Loss: 0.0166, Val Loss: 3.4966\n",
      "[Epoch 85/100] Train Loss: 0.0140, Val Loss: 3.1136\n",
      "[Epoch 90/100] Train Loss: 0.0311, Val Loss: 3.3088\n",
      "[Epoch 95/100] Train Loss: 0.0184, Val Loss: 3.9959\n",
      "[Epoch 100/100] Train Loss: 0.0129, Val Loss: 3.5119\n",
      "Accuracy on Nonzero Predictions: 0.4885\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_pca_lstm_lr0.011_options.png\n",
      "[0.5572519083969466, 0.5038167938931297, 0.48854961832061067]\n",
      "[-99.96163502137065, -99.91899498276511, -0.686936369400345]\n",
      "clean, gru, single_name\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/horizontal_structure/clean/single_name/AAPL/10y_5_data.pkl\n",
      "Training AAPL | LR: 0.009 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6937, Val Loss: 0.6961\n",
      "[Epoch 10/100] Train Loss: 0.6935, Val Loss: 0.6913\n",
      "[Epoch 15/100] Train Loss: 0.6924, Val Loss: 0.6950\n",
      "[Epoch 20/100] Train Loss: 0.6908, Val Loss: 0.6819\n",
      "[Epoch 25/100] Train Loss: 0.6803, Val Loss: 0.7062\n",
      "[Epoch 30/100] Train Loss: 0.6758, Val Loss: 0.6934\n",
      "[Epoch 35/100] Train Loss: 0.6672, Val Loss: 0.6791\n",
      "[Epoch 40/100] Train Loss: 0.6576, Val Loss: 0.6864\n",
      "[Epoch 45/100] Train Loss: 0.6467, Val Loss: 0.6687\n",
      "[Epoch 50/100] Train Loss: 0.6347, Val Loss: 0.6771\n",
      "[Epoch 55/100] Train Loss: 0.6338, Val Loss: 0.6917\n",
      "[Epoch 60/100] Train Loss: 0.6131, Val Loss: 0.7041\n",
      "[Epoch 65/100] Train Loss: 0.6129, Val Loss: 0.7265\n",
      "[Epoch 70/100] Train Loss: 0.5995, Val Loss: 0.7271\n",
      "[Epoch 75/100] Train Loss: 0.5997, Val Loss: 0.7490\n",
      "[Epoch 80/100] Train Loss: 0.5768, Val Loss: 0.7136\n",
      "[Epoch 85/100] Train Loss: 0.5709, Val Loss: 0.7308\n",
      "[Epoch 90/100] Train Loss: 0.5662, Val Loss: 0.7487\n",
      "[Epoch 95/100] Train Loss: 0.5696, Val Loss: 0.7376\n",
      "[Epoch 100/100] Train Loss: 0.5789, Val Loss: 0.7042\n",
      "Accuracy on Nonzero Predictions: 0.5191\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_gru_lr0.009_single_name.png\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.5643, Val Loss: 0.7955\n",
      "[Epoch 10/100] Train Loss: 0.5512, Val Loss: 0.7650\n",
      "[Epoch 15/100] Train Loss: 0.5509, Val Loss: 0.8309\n",
      "[Epoch 20/100] Train Loss: 0.5472, Val Loss: 0.6985\n",
      "[Epoch 25/100] Train Loss: 0.5354, Val Loss: 0.7369\n",
      "[Epoch 30/100] Train Loss: 0.5539, Val Loss: 0.7460\n",
      "[Epoch 35/100] Train Loss: 0.5273, Val Loss: 0.8830\n",
      "[Epoch 40/100] Train Loss: 0.5361, Val Loss: 0.7362\n",
      "[Epoch 45/100] Train Loss: 0.5116, Val Loss: 0.8401\n",
      "[Epoch 50/100] Train Loss: 0.5150, Val Loss: 0.8453\n",
      "[Epoch 55/100] Train Loss: 0.5146, Val Loss: 0.8123\n",
      "[Epoch 60/100] Train Loss: 0.5075, Val Loss: 0.9751\n",
      "[Epoch 65/100] Train Loss: 0.5032, Val Loss: 0.9100\n",
      "[Epoch 70/100] Train Loss: 0.5131, Val Loss: 0.7885\n",
      "[Epoch 75/100] Train Loss: 0.4976, Val Loss: 0.7457\n",
      "[Epoch 80/100] Train Loss: 0.4992, Val Loss: 0.8433\n",
      "[Epoch 85/100] Train Loss: 0.5034, Val Loss: 0.7870\n",
      "[Epoch 90/100] Train Loss: 0.4966, Val Loss: 0.8394\n",
      "[Epoch 95/100] Train Loss: 0.4916, Val Loss: 0.8629\n",
      "[Epoch 100/100] Train Loss: 0.4965, Val Loss: 0.7719\n",
      "Accuracy on Nonzero Predictions: 0.5267\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_gru_lr0.01_single_name.png\n",
      "Training AAPL | LR: 0.011 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.4939, Val Loss: 0.8231\n",
      "[Epoch 10/100] Train Loss: 0.4780, Val Loss: 0.8863\n",
      "[Epoch 15/100] Train Loss: 0.4790, Val Loss: 0.8269\n",
      "[Epoch 20/100] Train Loss: 0.4862, Val Loss: 0.8229\n",
      "[Epoch 25/100] Train Loss: 0.4866, Val Loss: 0.9622\n",
      "[Epoch 30/100] Train Loss: 0.4714, Val Loss: 0.8833\n",
      "[Epoch 35/100] Train Loss: 0.4701, Val Loss: 0.8463\n",
      "[Epoch 40/100] Train Loss: 0.4691, Val Loss: 0.7831\n",
      "[Epoch 45/100] Train Loss: 0.4970, Val Loss: 0.8747\n",
      "[Epoch 50/100] Train Loss: 0.4548, Val Loss: 0.9016\n",
      "[Epoch 55/100] Train Loss: 0.4632, Val Loss: 0.9030\n",
      "[Epoch 60/100] Train Loss: 0.4584, Val Loss: 0.9768\n",
      "[Epoch 65/100] Train Loss: 0.4577, Val Loss: 0.9145\n",
      "[Epoch 70/100] Train Loss: 0.4406, Val Loss: 0.9419\n",
      "[Epoch 75/100] Train Loss: 0.4538, Val Loss: 0.9014\n",
      "[Epoch 80/100] Train Loss: 0.4552, Val Loss: 1.0184\n",
      "[Epoch 85/100] Train Loss: 0.4544, Val Loss: 0.8794\n",
      "[Epoch 90/100] Train Loss: 0.4607, Val Loss: 0.9649\n",
      "[Epoch 95/100] Train Loss: 0.4477, Val Loss: 0.9427\n",
      "[Epoch 100/100] Train Loss: 0.4547, Val Loss: 0.8918\n",
      "Accuracy on Nonzero Predictions: 0.5038\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_gru_lr0.011_single_name.png\n",
      "[0.5190839694656488, 0.5267175572519084, 0.5038167938931297]\n",
      "[-16.792655875728922, -12.41467446432307, -9.154734618234418]\n",
      "pca, gru, technical\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/horizontal_structure/pca/technical/AAPL/10y_5_data.pkl\n",
      "Training AAPL | LR: 0.009 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6938, Val Loss: 0.6817\n",
      "[Epoch 10/100] Train Loss: 0.6936, Val Loss: 0.6876\n",
      "[Epoch 15/100] Train Loss: 0.6912, Val Loss: 0.7136\n",
      "[Epoch 20/100] Train Loss: 0.7061, Val Loss: 0.7718\n",
      "[Epoch 25/100] Train Loss: 0.7006, Val Loss: 0.6827\n",
      "[Epoch 30/100] Train Loss: 0.7001, Val Loss: 0.6819\n",
      "[Epoch 35/100] Train Loss: 0.6979, Val Loss: 0.6725\n",
      "[Epoch 40/100] Train Loss: 0.6954, Val Loss: 0.6823\n",
      "[Epoch 45/100] Train Loss: 0.6952, Val Loss: 0.6777\n",
      "[Epoch 50/100] Train Loss: 0.6933, Val Loss: 0.6947\n",
      "[Epoch 55/100] Train Loss: 0.6912, Val Loss: 0.6894\n",
      "[Epoch 60/100] Train Loss: 0.6929, Val Loss: 0.6753\n",
      "[Epoch 65/100] Train Loss: 0.6879, Val Loss: 0.7050\n",
      "[Epoch 70/100] Train Loss: 0.6931, Val Loss: 0.6888\n",
      "[Epoch 75/100] Train Loss: 0.6968, Val Loss: 0.6964\n",
      "[Epoch 80/100] Train Loss: 0.6952, Val Loss: 0.6714\n",
      "[Epoch 85/100] Train Loss: 0.6941, Val Loss: 0.6882\n",
      "[Epoch 90/100] Train Loss: 0.6919, Val Loss: 0.6948\n",
      "[Epoch 95/100] Train Loss: 0.6936, Val Loss: 0.6886\n",
      "[Epoch 100/100] Train Loss: 0.6931, Val Loss: 0.6879\n",
      "Accuracy on Nonzero Predictions: 0.5317\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_pca_gru_lr0.009_technical.png\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6923, Val Loss: 0.6953\n",
      "[Epoch 10/100] Train Loss: 0.6938, Val Loss: 0.6861\n",
      "[Epoch 15/100] Train Loss: 0.6926, Val Loss: 0.6855\n",
      "[Epoch 20/100] Train Loss: 0.6903, Val Loss: 0.7013\n",
      "[Epoch 25/100] Train Loss: 0.6880, Val Loss: 0.7049\n",
      "[Epoch 30/100] Train Loss: 0.6900, Val Loss: 0.7137\n",
      "[Epoch 35/100] Train Loss: 0.6873, Val Loss: 0.7038\n",
      "[Epoch 40/100] Train Loss: 0.6885, Val Loss: 0.7225\n",
      "[Epoch 45/100] Train Loss: 0.6859, Val Loss: 0.7240\n",
      "[Epoch 50/100] Train Loss: 0.6825, Val Loss: 0.7235\n",
      "[Epoch 55/100] Train Loss: 0.6821, Val Loss: 0.7170\n",
      "[Epoch 60/100] Train Loss: 0.6813, Val Loss: 0.7160\n",
      "[Epoch 65/100] Train Loss: 0.6906, Val Loss: 0.6924\n",
      "[Epoch 70/100] Train Loss: 0.6789, Val Loss: 0.7150\n",
      "[Epoch 75/100] Train Loss: 0.6838, Val Loss: 0.7039\n",
      "[Epoch 80/100] Train Loss: 0.6857, Val Loss: 0.6972\n",
      "[Epoch 85/100] Train Loss: 0.6832, Val Loss: 0.6904\n",
      "[Epoch 90/100] Train Loss: 0.6844, Val Loss: 0.7186\n",
      "[Epoch 95/100] Train Loss: 0.6826, Val Loss: 0.7169\n",
      "[Epoch 100/100] Train Loss: 0.6920, Val Loss: 0.7007\n",
      "Accuracy on Nonzero Predictions: 0.5794\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_pca_gru_lr0.01_technical.png\n",
      "Training AAPL | LR: 0.011 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6813, Val Loss: 0.7177\n",
      "[Epoch 10/100] Train Loss: 0.6839, Val Loss: 0.7112\n",
      "[Epoch 15/100] Train Loss: 0.6836, Val Loss: 0.7044\n",
      "[Epoch 20/100] Train Loss: 0.6827, Val Loss: 0.7045\n",
      "[Epoch 25/100] Train Loss: 0.6824, Val Loss: 0.6978\n",
      "[Epoch 30/100] Train Loss: 0.6858, Val Loss: 0.6869\n",
      "[Epoch 35/100] Train Loss: 0.6895, Val Loss: 0.7161\n",
      "[Epoch 40/100] Train Loss: 0.6872, Val Loss: 0.6933\n",
      "[Epoch 45/100] Train Loss: 0.6871, Val Loss: 0.7032\n",
      "[Epoch 50/100] Train Loss: 0.6878, Val Loss: 0.7133\n",
      "[Epoch 55/100] Train Loss: 0.6936, Val Loss: 0.7047\n",
      "[Epoch 60/100] Train Loss: 0.6908, Val Loss: 0.6951\n",
      "[Epoch 65/100] Train Loss: 0.6918, Val Loss: 0.6932\n",
      "[Epoch 70/100] Train Loss: 0.6905, Val Loss: 0.7179\n",
      "[Epoch 75/100] Train Loss: 0.6926, Val Loss: 0.7217\n",
      "[Epoch 80/100] Train Loss: 0.6917, Val Loss: 0.7077\n",
      "[Epoch 85/100] Train Loss: 0.6924, Val Loss: 0.6952\n",
      "[Epoch 90/100] Train Loss: 0.6899, Val Loss: 0.6859\n",
      "[Epoch 95/100] Train Loss: 0.6891, Val Loss: 0.7014\n",
      "[Epoch 100/100] Train Loss: 0.6805, Val Loss: 0.7031\n",
      "Accuracy on Nonzero Predictions: 0.4286\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_pca_gru_lr0.011_technical.png\n",
      "[0.5317460317460317, 0.5793650793650794, 0.42857142857142855]\n",
      "[-0.4192388856678447, -0.31321320314540524, -1.065557371583325]\n",
      "pca, gru, options\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/horizontal_structure/pca/options/AAPL/10y_5_data.pkl\n",
      "Training AAPL | LR: 0.009 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6908, Val Loss: 0.6938\n",
      "[Epoch 10/100] Train Loss: 0.6919, Val Loss: 0.6821\n",
      "[Epoch 15/100] Train Loss: 0.6818, Val Loss: 0.7279\n",
      "[Epoch 20/100] Train Loss: 0.6829, Val Loss: 0.6762\n",
      "[Epoch 25/100] Train Loss: 0.6817, Val Loss: 0.6730\n",
      "[Epoch 30/100] Train Loss: 0.6830, Val Loss: 0.6793\n",
      "[Epoch 35/100] Train Loss: 0.6770, Val Loss: 0.6710\n",
      "[Epoch 40/100] Train Loss: 0.6701, Val Loss: 0.6670\n",
      "[Epoch 45/100] Train Loss: 0.6715, Val Loss: 0.6700\n",
      "[Epoch 50/100] Train Loss: 0.6636, Val Loss: 0.6776\n",
      "[Epoch 55/100] Train Loss: 0.6578, Val Loss: 0.6826\n",
      "[Epoch 60/100] Train Loss: 0.6541, Val Loss: 0.7180\n",
      "[Epoch 65/100] Train Loss: 0.6424, Val Loss: 0.7314\n",
      "[Epoch 70/100] Train Loss: 0.6207, Val Loss: 0.7897\n",
      "[Epoch 75/100] Train Loss: 0.6379, Val Loss: 0.8810\n",
      "[Epoch 80/100] Train Loss: 0.6115, Val Loss: 0.9711\n",
      "[Epoch 85/100] Train Loss: 0.5805, Val Loss: 1.1921\n",
      "[Epoch 90/100] Train Loss: 0.5728, Val Loss: 1.1175\n",
      "[Epoch 95/100] Train Loss: 0.5565, Val Loss: 1.0781\n",
      "[Epoch 100/100] Train Loss: 0.5375, Val Loss: 0.9918\n",
      "Accuracy on Nonzero Predictions: 0.5954\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_pca_gru_lr0.009_options.png\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.5085, Val Loss: 1.2982\n",
      "[Epoch 10/100] Train Loss: 0.4835, Val Loss: 1.3433\n",
      "[Epoch 15/100] Train Loss: 0.4544, Val Loss: 1.5462\n",
      "[Epoch 20/100] Train Loss: 0.4648, Val Loss: 1.6853\n",
      "[Epoch 25/100] Train Loss: 0.4310, Val Loss: 1.6521\n",
      "[Epoch 30/100] Train Loss: 0.4157, Val Loss: 1.8291\n",
      "[Epoch 35/100] Train Loss: 0.4263, Val Loss: 1.6292\n",
      "[Epoch 40/100] Train Loss: 0.4040, Val Loss: 1.6613\n",
      "[Epoch 45/100] Train Loss: 0.3960, Val Loss: 1.6771\n",
      "[Epoch 50/100] Train Loss: 0.3950, Val Loss: 1.6372\n",
      "[Epoch 55/100] Train Loss: 0.3871, Val Loss: 1.8126\n",
      "[Epoch 60/100] Train Loss: 0.3780, Val Loss: 2.1709\n",
      "[Epoch 65/100] Train Loss: 0.3422, Val Loss: 2.3114\n",
      "[Epoch 70/100] Train Loss: 0.3474, Val Loss: 2.3281\n",
      "[Epoch 75/100] Train Loss: 0.3147, Val Loss: 2.0703\n",
      "[Epoch 80/100] Train Loss: 0.3161, Val Loss: 2.1075\n",
      "[Epoch 85/100] Train Loss: 0.2870, Val Loss: 2.5818\n",
      "[Epoch 90/100] Train Loss: 0.3332, Val Loss: 2.1390\n",
      "[Epoch 95/100] Train Loss: 0.3005, Val Loss: 2.1322\n",
      "[Epoch 100/100] Train Loss: 0.2798, Val Loss: 2.2076\n",
      "Accuracy on Nonzero Predictions: 0.5496\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_pca_gru_lr0.01_options.png\n",
      "Training AAPL | LR: 0.011 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.3261, Val Loss: 2.4806\n",
      "[Epoch 10/100] Train Loss: 0.3030, Val Loss: 2.0734\n",
      "[Epoch 15/100] Train Loss: 0.2648, Val Loss: 1.7170\n",
      "[Epoch 20/100] Train Loss: 0.3016, Val Loss: 2.0795\n",
      "[Epoch 25/100] Train Loss: 0.2684, Val Loss: 2.2461\n",
      "[Epoch 30/100] Train Loss: 0.2868, Val Loss: 2.2955\n",
      "[Epoch 35/100] Train Loss: 0.2952, Val Loss: 2.5744\n",
      "[Epoch 40/100] Train Loss: 0.2739, Val Loss: 2.5355\n",
      "[Epoch 45/100] Train Loss: 0.3040, Val Loss: 2.1355\n",
      "[Epoch 50/100] Train Loss: 0.2687, Val Loss: 2.2955\n",
      "[Epoch 55/100] Train Loss: 0.2593, Val Loss: 2.1996\n",
      "[Epoch 60/100] Train Loss: 0.2481, Val Loss: 2.4593\n",
      "[Epoch 65/100] Train Loss: 0.2129, Val Loss: 2.4244\n",
      "[Epoch 70/100] Train Loss: 0.2406, Val Loss: 2.3859\n",
      "[Epoch 75/100] Train Loss: 0.3110, Val Loss: 1.9257\n",
      "[Epoch 80/100] Train Loss: 0.2413, Val Loss: 2.1429\n",
      "[Epoch 85/100] Train Loss: 0.2481, Val Loss: 2.1850\n",
      "[Epoch 90/100] Train Loss: 0.2607, Val Loss: 2.0083\n",
      "[Epoch 95/100] Train Loss: 0.2680, Val Loss: 1.8549\n",
      "[Epoch 100/100] Train Loss: 0.2374, Val Loss: 2.1079\n",
      "Accuracy on Nonzero Predictions: 0.5878\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_pca_gru_lr0.011_options.png\n",
      "[0.5954198473282443, 0.549618320610687, 0.5877862595419847]\n",
      "[-22.8951912405555, -47.6925169823348, -16.939510121364027]\n",
      "clean, lstm, single_name\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/horizontal_structure/clean/single_name/AAPL/10y_5_data.pkl\n",
      "Training AAPL | LR: 0.009 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6934, Val Loss: 0.6915\n",
      "[Epoch 10/100] Train Loss: 0.6917, Val Loss: 0.6926\n",
      "[Epoch 15/100] Train Loss: 0.6895, Val Loss: 0.6910\n",
      "[Epoch 20/100] Train Loss: 0.6879, Val Loss: 0.6874\n",
      "[Epoch 25/100] Train Loss: 0.6845, Val Loss: 0.6832\n",
      "[Epoch 30/100] Train Loss: 0.6797, Val Loss: 0.6802\n",
      "[Epoch 35/100] Train Loss: 0.6758, Val Loss: 0.6787\n",
      "[Epoch 40/100] Train Loss: 0.6723, Val Loss: 0.6762\n",
      "[Epoch 45/100] Train Loss: 0.6695, Val Loss: 0.6724\n",
      "[Epoch 50/100] Train Loss: 0.6669, Val Loss: 0.6682\n",
      "[Epoch 55/100] Train Loss: 0.6633, Val Loss: 0.6659\n",
      "[Epoch 60/100] Train Loss: 0.6591, Val Loss: 0.6680\n",
      "[Epoch 65/100] Train Loss: 0.6548, Val Loss: 0.6716\n",
      "[Epoch 70/100] Train Loss: 0.6508, Val Loss: 0.6765\n",
      "[Epoch 75/100] Train Loss: 0.6471, Val Loss: 0.6819\n",
      "[Epoch 80/100] Train Loss: 0.6420, Val Loss: 0.6977\n",
      "[Epoch 85/100] Train Loss: 0.6348, Val Loss: 0.7160\n",
      "[Epoch 90/100] Train Loss: 0.6285, Val Loss: 0.7243\n",
      "[Epoch 95/100] Train Loss: 0.6217, Val Loss: 0.7328\n",
      "[Epoch 100/100] Train Loss: 0.6152, Val Loss: 0.7449\n",
      "Accuracy on Nonzero Predictions: 0.5115\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_lstm_lr0.009_single_name.png\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6080, Val Loss: 0.7525\n",
      "[Epoch 10/100] Train Loss: 0.6032, Val Loss: 0.7616\n",
      "[Epoch 15/100] Train Loss: 0.5986, Val Loss: 0.7703\n",
      "[Epoch 20/100] Train Loss: 0.5939, Val Loss: 0.7819\n",
      "[Epoch 25/100] Train Loss: 0.5892, Val Loss: 0.7952\n",
      "[Epoch 30/100] Train Loss: 0.5847, Val Loss: 0.8075\n",
      "[Epoch 35/100] Train Loss: 0.5807, Val Loss: 0.8185\n",
      "[Epoch 40/100] Train Loss: 0.5770, Val Loss: 0.8284\n",
      "[Epoch 45/100] Train Loss: 0.5733, Val Loss: 0.8369\n",
      "[Epoch 50/100] Train Loss: 0.5700, Val Loss: 0.8463\n",
      "[Epoch 55/100] Train Loss: 0.5658, Val Loss: 0.8549\n",
      "[Epoch 60/100] Train Loss: 0.5617, Val Loss: 0.8652\n",
      "[Epoch 65/100] Train Loss: 0.5574, Val Loss: 0.8782\n",
      "[Epoch 70/100] Train Loss: 0.5528, Val Loss: 0.8945\n",
      "[Epoch 75/100] Train Loss: 0.5477, Val Loss: 0.9122\n",
      "[Epoch 80/100] Train Loss: 0.5428, Val Loss: 0.9313\n",
      "[Epoch 85/100] Train Loss: 0.5384, Val Loss: 0.9473\n",
      "[Epoch 90/100] Train Loss: 0.5344, Val Loss: 0.9560\n",
      "[Epoch 95/100] Train Loss: 0.5307, Val Loss: 0.9605\n",
      "[Epoch 100/100] Train Loss: 0.5271, Val Loss: 0.9625\n",
      "Accuracy on Nonzero Predictions: 0.3893\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_lstm_lr0.01_single_name.png\n",
      "Training AAPL | LR: 0.011 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.5253, Val Loss: 0.9648\n",
      "[Epoch 10/100] Train Loss: 0.5226, Val Loss: 0.9674\n",
      "[Epoch 15/100] Train Loss: 0.5199, Val Loss: 0.9716\n",
      "[Epoch 20/100] Train Loss: 0.5173, Val Loss: 0.9763\n",
      "[Epoch 25/100] Train Loss: 0.5147, Val Loss: 0.9813\n",
      "[Epoch 30/100] Train Loss: 0.5121, Val Loss: 0.9858\n",
      "[Epoch 35/100] Train Loss: 0.5097, Val Loss: 0.9883\n",
      "[Epoch 40/100] Train Loss: 0.5073, Val Loss: 0.9886\n",
      "[Epoch 45/100] Train Loss: 0.5048, Val Loss: 0.9919\n",
      "[Epoch 50/100] Train Loss: 0.5024, Val Loss: 0.9977\n",
      "[Epoch 55/100] Train Loss: 0.5046, Val Loss: 1.0030\n",
      "[Epoch 60/100] Train Loss: 0.4996, Val Loss: 1.0092\n",
      "[Epoch 65/100] Train Loss: 0.5012, Val Loss: 1.0087\n",
      "[Epoch 70/100] Train Loss: 0.4930, Val Loss: 1.0147\n",
      "[Epoch 75/100] Train Loss: 0.4901, Val Loss: 1.0188\n",
      "[Epoch 80/100] Train Loss: 0.4875, Val Loss: 1.0230\n",
      "[Epoch 85/100] Train Loss: 0.4852, Val Loss: 1.0271\n",
      "[Epoch 90/100] Train Loss: 0.4828, Val Loss: 1.0304\n",
      "[Epoch 95/100] Train Loss: 0.4816, Val Loss: 1.0354\n",
      "[Epoch 100/100] Train Loss: 0.4779, Val Loss: 1.0443\n",
      "Accuracy on Nonzero Predictions: 0.4885\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_lstm_lr0.011_single_name.png\n",
      "[0.5114503816793893, 0.3893129770992366, 0.48854961832061067]\n",
      "[-11.550413912684116, -14.545753596412458, -10.600531244732844]\n",
      "clean, lstm, technical\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/horizontal_structure/clean/technical/AAPL/10y_5_data.pkl\n",
      "Training AAPL | LR: 0.009 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6930, Val Loss: 0.6927\n",
      "[Epoch 10/100] Train Loss: 0.6847, Val Loss: 0.7121\n",
      "[Epoch 15/100] Train Loss: 0.6521, Val Loss: 0.7416\n",
      "[Epoch 20/100] Train Loss: 0.5528, Val Loss: 0.7981\n",
      "[Epoch 25/100] Train Loss: 0.4558, Val Loss: 1.1176\n",
      "[Epoch 30/100] Train Loss: 0.3720, Val Loss: 1.1487\n",
      "[Epoch 35/100] Train Loss: 0.2858, Val Loss: 1.4474\n",
      "[Epoch 40/100] Train Loss: 0.2074, Val Loss: 1.7580\n",
      "[Epoch 45/100] Train Loss: 0.1700, Val Loss: 2.1497\n",
      "[Epoch 50/100] Train Loss: 0.1320, Val Loss: 2.2471\n",
      "[Epoch 55/100] Train Loss: 0.0809, Val Loss: 2.5417\n",
      "[Epoch 60/100] Train Loss: 0.0959, Val Loss: 2.8123\n",
      "[Epoch 65/100] Train Loss: 0.0725, Val Loss: 2.3319\n",
      "[Epoch 70/100] Train Loss: 0.0445, Val Loss: 2.5149\n",
      "[Epoch 75/100] Train Loss: 0.0674, Val Loss: 2.6787\n",
      "[Epoch 80/100] Train Loss: 0.1270, Val Loss: 2.8613\n",
      "[Epoch 85/100] Train Loss: 0.0652, Val Loss: 3.2304\n",
      "[Epoch 90/100] Train Loss: 0.0344, Val Loss: 3.3497\n",
      "[Epoch 95/100] Train Loss: 0.0525, Val Loss: 3.4957\n",
      "[Epoch 100/100] Train Loss: 0.0623, Val Loss: 3.2482\n",
      "Accuracy on Nonzero Predictions: 0.5238\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_lstm_lr0.009_technical.png\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.0552, Val Loss: 3.8846\n",
      "[Epoch 10/100] Train Loss: 0.0990, Val Loss: 3.4486\n",
      "[Epoch 15/100] Train Loss: 0.0547, Val Loss: 3.2830\n",
      "[Epoch 20/100] Train Loss: 0.0350, Val Loss: 3.9525\n",
      "[Epoch 25/100] Train Loss: 0.0496, Val Loss: 3.7888\n",
      "[Epoch 30/100] Train Loss: 0.1241, Val Loss: 4.3597\n",
      "[Epoch 35/100] Train Loss: 0.0551, Val Loss: 3.8259\n",
      "[Epoch 40/100] Train Loss: 0.0706, Val Loss: 3.5573\n",
      "[Epoch 45/100] Train Loss: 0.0550, Val Loss: 4.0413\n",
      "[Epoch 50/100] Train Loss: 0.0569, Val Loss: 4.2690\n",
      "[Epoch 55/100] Train Loss: 0.0582, Val Loss: 4.1031\n",
      "[Epoch 60/100] Train Loss: 0.0576, Val Loss: 4.5606\n",
      "[Epoch 65/100] Train Loss: 0.0514, Val Loss: 4.1947\n",
      "[Epoch 70/100] Train Loss: 0.0583, Val Loss: 4.7340\n",
      "[Epoch 75/100] Train Loss: 0.0865, Val Loss: 4.3517\n",
      "[Epoch 80/100] Train Loss: 0.0629, Val Loss: 3.8690\n",
      "[Epoch 85/100] Train Loss: 0.0371, Val Loss: 4.0685\n",
      "[Epoch 90/100] Train Loss: 0.0747, Val Loss: 4.3114\n",
      "[Epoch 95/100] Train Loss: 0.1037, Val Loss: 4.0680\n",
      "[Epoch 100/100] Train Loss: 0.0542, Val Loss: 3.4117\n",
      "Accuracy on Nonzero Predictions: 0.5317\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_lstm_lr0.01_technical.png\n",
      "Training AAPL | LR: 0.011 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.1017, Val Loss: 3.2805\n",
      "[Epoch 10/100] Train Loss: 0.0755, Val Loss: 3.5774\n",
      "[Epoch 15/100] Train Loss: 0.0484, Val Loss: 3.2637\n",
      "[Epoch 20/100] Train Loss: 0.0786, Val Loss: 3.6122\n",
      "[Epoch 25/100] Train Loss: 0.0378, Val Loss: 4.1683\n",
      "[Epoch 30/100] Train Loss: 0.1051, Val Loss: 3.5546\n",
      "[Epoch 35/100] Train Loss: 0.0510, Val Loss: 3.7499\n",
      "[Epoch 40/100] Train Loss: 0.1126, Val Loss: 4.0203\n",
      "[Epoch 45/100] Train Loss: 0.0551, Val Loss: 3.7710\n",
      "[Epoch 50/100] Train Loss: 0.0545, Val Loss: 3.3123\n",
      "[Epoch 55/100] Train Loss: 0.0711, Val Loss: 3.8161\n",
      "[Epoch 60/100] Train Loss: 0.0430, Val Loss: 3.8660\n",
      "[Epoch 65/100] Train Loss: 0.0199, Val Loss: 3.2461\n",
      "[Epoch 70/100] Train Loss: 0.0659, Val Loss: 3.5051\n",
      "[Epoch 75/100] Train Loss: 0.0902, Val Loss: 3.4973\n",
      "[Epoch 80/100] Train Loss: 0.0621, Val Loss: 3.9207\n",
      "[Epoch 85/100] Train Loss: 0.0731, Val Loss: 3.5291\n",
      "[Epoch 90/100] Train Loss: 0.0654, Val Loss: 3.7533\n",
      "[Epoch 95/100] Train Loss: 0.0277, Val Loss: 3.9345\n",
      "[Epoch 100/100] Train Loss: 0.0402, Val Loss: 4.0210\n",
      "Accuracy on Nonzero Predictions: 0.5873\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_lstm_lr0.011_technical.png\n",
      "[0.5238095238095238, 0.5317460317460317, 0.5873015873015873]\n",
      "[-91.03890838083457, 1.3335545716834325, -52.62435661804824]\n",
      "clean, lstm, options\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/horizontal_structure/clean/options/AAPL/10y_5_data.pkl\n",
      "Training AAPL | LR: 0.009 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6892, Val Loss: 0.6829\n",
      "[Epoch 10/100] Train Loss: 0.6818, Val Loss: 0.6882\n",
      "[Epoch 15/100] Train Loss: 0.6521, Val Loss: 0.6810\n",
      "[Epoch 20/100] Train Loss: 0.5449, Val Loss: 0.7579\n",
      "[Epoch 25/100] Train Loss: 0.4099, Val Loss: 0.8192\n",
      "[Epoch 30/100] Train Loss: 0.3106, Val Loss: 1.0505\n",
      "[Epoch 35/100] Train Loss: 0.2360, Val Loss: 1.1664\n",
      "[Epoch 40/100] Train Loss: 0.1615, Val Loss: 1.4256\n",
      "[Epoch 45/100] Train Loss: 0.1069, Val Loss: 1.5860\n",
      "[Epoch 50/100] Train Loss: 0.0720, Val Loss: 1.8157\n",
      "[Epoch 55/100] Train Loss: 0.0657, Val Loss: 1.8589\n",
      "[Epoch 60/100] Train Loss: 0.0777, Val Loss: 1.9371\n",
      "[Epoch 65/100] Train Loss: 0.0276, Val Loss: 2.1768\n",
      "[Epoch 70/100] Train Loss: 0.0385, Val Loss: 2.1017\n",
      "[Epoch 75/100] Train Loss: 0.0387, Val Loss: 2.1581\n",
      "[Epoch 80/100] Train Loss: 0.0842, Val Loss: 2.3816\n",
      "[Epoch 85/100] Train Loss: 0.0843, Val Loss: 2.2093\n",
      "[Epoch 90/100] Train Loss: 0.0231, Val Loss: 2.4853\n",
      "[Epoch 95/100] Train Loss: 0.0285, Val Loss: 2.6213\n",
      "[Epoch 100/100] Train Loss: 0.0240, Val Loss: 2.3774\n",
      "Accuracy on Nonzero Predictions: 0.5344\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_lstm_lr0.009_options.png\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.0443, Val Loss: 2.2305\n",
      "[Epoch 10/100] Train Loss: 0.0421, Val Loss: 3.0306\n",
      "[Epoch 15/100] Train Loss: 0.0299, Val Loss: 2.5434\n",
      "[Epoch 20/100] Train Loss: 0.0631, Val Loss: 2.7516\n",
      "[Epoch 25/100] Train Loss: 0.0746, Val Loss: 2.8890\n",
      "[Epoch 30/100] Train Loss: 0.0365, Val Loss: 3.1856\n",
      "[Epoch 35/100] Train Loss: 0.0321, Val Loss: 3.4125\n",
      "[Epoch 40/100] Train Loss: 0.0453, Val Loss: 2.8044\n",
      "[Epoch 45/100] Train Loss: 0.0697, Val Loss: 2.6146\n",
      "[Epoch 50/100] Train Loss: 0.0616, Val Loss: 2.6263\n",
      "[Epoch 55/100] Train Loss: 0.0212, Val Loss: 3.2392\n",
      "[Epoch 60/100] Train Loss: 0.0008, Val Loss: 3.4392\n",
      "[Epoch 65/100] Train Loss: 0.0005, Val Loss: 3.5281\n",
      "[Epoch 70/100] Train Loss: 0.0004, Val Loss: 3.5935\n",
      "[Epoch 75/100] Train Loss: 0.0003, Val Loss: 3.6540\n",
      "[Epoch 80/100] Train Loss: 0.0002, Val Loss: 3.7130\n",
      "[Epoch 85/100] Train Loss: 0.0002, Val Loss: 3.7736\n",
      "[Epoch 90/100] Train Loss: 0.0001, Val Loss: 3.8367\n",
      "[Epoch 95/100] Train Loss: 0.0001, Val Loss: 3.8975\n",
      "[Epoch 100/100] Train Loss: 0.0001, Val Loss: 3.9497\n",
      "Accuracy on Nonzero Predictions: 0.4275\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_lstm_lr0.01_options.png\n",
      "Training AAPL | LR: 0.011 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.0547, Val Loss: 3.3801\n",
      "[Epoch 10/100] Train Loss: 0.0883, Val Loss: 3.2185\n",
      "[Epoch 15/100] Train Loss: 0.0893, Val Loss: 2.6368\n",
      "[Epoch 20/100] Train Loss: 0.0418, Val Loss: 2.9290\n",
      "[Epoch 25/100] Train Loss: 0.0583, Val Loss: 2.5934\n",
      "[Epoch 30/100] Train Loss: 0.0379, Val Loss: 3.1018\n",
      "[Epoch 35/100] Train Loss: 0.0264, Val Loss: 2.7749\n",
      "[Epoch 40/100] Train Loss: 0.0738, Val Loss: 3.3016\n",
      "[Epoch 45/100] Train Loss: 0.0476, Val Loss: 2.7750\n",
      "[Epoch 50/100] Train Loss: 0.0479, Val Loss: 3.1924\n",
      "[Epoch 55/100] Train Loss: 0.0091, Val Loss: 3.6581\n",
      "[Epoch 60/100] Train Loss: 0.0830, Val Loss: 2.6948\n",
      "[Epoch 65/100] Train Loss: 0.0570, Val Loss: 3.3683\n",
      "[Epoch 70/100] Train Loss: 0.0375, Val Loss: 3.0912\n",
      "[Epoch 75/100] Train Loss: 0.0114, Val Loss: 2.6987\n",
      "[Epoch 80/100] Train Loss: 0.0802, Val Loss: 2.7091\n",
      "[Epoch 85/100] Train Loss: 0.0550, Val Loss: 2.6749\n",
      "[Epoch 90/100] Train Loss: 0.0311, Val Loss: 2.8491\n",
      "[Epoch 95/100] Train Loss: 0.0183, Val Loss: 3.2593\n",
      "[Epoch 100/100] Train Loss: 0.0330, Val Loss: 3.5737\n",
      "Accuracy on Nonzero Predictions: 0.5115\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_lstm_lr0.011_options.png\n",
      "[0.5343511450381679, 0.42748091603053434, 0.5114503816793893]\n",
      "[-96.54213977337199, -99.78680791459159, 23.926010035884303]\n",
      "clean, gru, single_name\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/horizontal_structure/clean/single_name/AAPL/10y_5_data.pkl\n",
      "Training AAPL | LR: 0.009 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6935, Val Loss: 0.6939\n",
      "[Epoch 10/100] Train Loss: 0.6931, Val Loss: 0.6949\n",
      "[Epoch 15/100] Train Loss: 0.6893, Val Loss: 0.6965\n",
      "[Epoch 20/100] Train Loss: 0.6866, Val Loss: 0.6891\n",
      "[Epoch 25/100] Train Loss: 0.6795, Val Loss: 0.7114\n",
      "[Epoch 30/100] Train Loss: 0.6761, Val Loss: 0.6954\n",
      "[Epoch 35/100] Train Loss: 0.6686, Val Loss: 0.6963\n",
      "[Epoch 40/100] Train Loss: 0.6581, Val Loss: 0.6984\n",
      "[Epoch 45/100] Train Loss: 0.6514, Val Loss: 0.6965\n",
      "[Epoch 50/100] Train Loss: 0.6459, Val Loss: 0.6966\n",
      "[Epoch 55/100] Train Loss: 0.6358, Val Loss: 0.6929\n",
      "[Epoch 60/100] Train Loss: 0.6300, Val Loss: 0.7089\n",
      "[Epoch 65/100] Train Loss: 0.6231, Val Loss: 0.7075\n",
      "[Epoch 70/100] Train Loss: 0.6235, Val Loss: 0.7037\n",
      "[Epoch 75/100] Train Loss: 0.6109, Val Loss: 0.6893\n",
      "[Epoch 80/100] Train Loss: 0.6079, Val Loss: 0.7270\n",
      "[Epoch 85/100] Train Loss: 0.5997, Val Loss: 0.7221\n",
      "[Epoch 90/100] Train Loss: 0.5908, Val Loss: 0.7153\n",
      "[Epoch 95/100] Train Loss: 0.5844, Val Loss: 0.7225\n",
      "[Epoch 100/100] Train Loss: 0.5800, Val Loss: 0.7157\n",
      "Accuracy on Nonzero Predictions: 0.4885\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_gru_lr0.009_single_name.png\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.5654, Val Loss: 0.7383\n",
      "[Epoch 10/100] Train Loss: 0.5800, Val Loss: 0.7248\n",
      "[Epoch 15/100] Train Loss: 0.5613, Val Loss: 0.7087\n",
      "[Epoch 20/100] Train Loss: 0.5629, Val Loss: 0.7220\n",
      "[Epoch 25/100] Train Loss: 0.5514, Val Loss: 0.7495\n",
      "[Epoch 30/100] Train Loss: 0.5482, Val Loss: 0.7790\n",
      "[Epoch 35/100] Train Loss: 0.5502, Val Loss: 0.7379\n",
      "[Epoch 40/100] Train Loss: 0.5455, Val Loss: 0.7238\n",
      "[Epoch 45/100] Train Loss: 0.5447, Val Loss: 0.7255\n",
      "[Epoch 50/100] Train Loss: 0.5400, Val Loss: 0.7266\n",
      "[Epoch 55/100] Train Loss: 0.5263, Val Loss: 0.7422\n",
      "[Epoch 60/100] Train Loss: 0.5096, Val Loss: 0.7165\n",
      "[Epoch 65/100] Train Loss: 0.5265, Val Loss: 0.7704\n",
      "[Epoch 70/100] Train Loss: 0.5136, Val Loss: 0.7148\n",
      "[Epoch 75/100] Train Loss: 0.5098, Val Loss: 0.7202\n",
      "[Epoch 80/100] Train Loss: 0.5028, Val Loss: 0.7343\n",
      "[Epoch 85/100] Train Loss: 0.5176, Val Loss: 0.7230\n",
      "[Epoch 90/100] Train Loss: 0.5005, Val Loss: 0.7308\n",
      "[Epoch 95/100] Train Loss: 0.5182, Val Loss: 0.7318\n",
      "[Epoch 100/100] Train Loss: 0.5062, Val Loss: 0.7165\n",
      "Accuracy on Nonzero Predictions: 0.4962\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_gru_lr0.01_single_name.png\n",
      "Training AAPL | LR: 0.011 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.4993, Val Loss: 0.7471\n",
      "[Epoch 10/100] Train Loss: 0.4888, Val Loss: 0.7316\n",
      "[Epoch 15/100] Train Loss: 0.4993, Val Loss: 0.7737\n",
      "[Epoch 20/100] Train Loss: 0.4921, Val Loss: 0.7191\n",
      "[Epoch 25/100] Train Loss: 0.4720, Val Loss: 0.7311\n",
      "[Epoch 30/100] Train Loss: 0.4878, Val Loss: 0.6631\n",
      "[Epoch 35/100] Train Loss: 0.4842, Val Loss: 0.7468\n",
      "[Epoch 40/100] Train Loss: 0.4811, Val Loss: 0.7178\n",
      "[Epoch 45/100] Train Loss: 0.4961, Val Loss: 0.7339\n",
      "[Epoch 50/100] Train Loss: 0.4868, Val Loss: 0.7093\n",
      "[Epoch 55/100] Train Loss: 0.4623, Val Loss: 0.7791\n",
      "[Epoch 60/100] Train Loss: 0.4830, Val Loss: 0.6995\n",
      "[Epoch 65/100] Train Loss: 0.4614, Val Loss: 0.7680\n",
      "[Epoch 70/100] Train Loss: 0.4654, Val Loss: 0.8270\n",
      "[Epoch 75/100] Train Loss: 0.4506, Val Loss: 0.8079\n",
      "[Epoch 80/100] Train Loss: 0.4607, Val Loss: 0.8237\n",
      "[Epoch 85/100] Train Loss: 0.4580, Val Loss: 0.7457\n",
      "[Epoch 90/100] Train Loss: 0.4645, Val Loss: 0.8258\n",
      "[Epoch 95/100] Train Loss: 0.4461, Val Loss: 0.7804\n",
      "[Epoch 100/100] Train Loss: 0.4488, Val Loss: 0.7785\n",
      "Accuracy on Nonzero Predictions: 0.5496\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_gru_lr0.011_single_name.png\n",
      "[0.48854961832061067, 0.4961832061068702, 0.549618320610687]\n",
      "[-16.637848470971882, -12.994511055876051, -12.723667924155496]\n",
      "clean, gru, technical\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/horizontal_structure/clean/technical/AAPL/10y_5_data.pkl\n",
      "Training AAPL | LR: 0.009 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.7075, Val Loss: 0.7982\n",
      "[Epoch 10/100] Train Loss: 0.7029, Val Loss: 0.6776\n",
      "[Epoch 15/100] Train Loss: 0.7042, Val Loss: 0.6895\n",
      "[Epoch 20/100] Train Loss: 0.7099, Val Loss: 0.6720\n",
      "[Epoch 25/100] Train Loss: 0.6990, Val Loss: 0.6856\n",
      "[Epoch 30/100] Train Loss: 0.6979, Val Loss: 0.6915\n",
      "[Epoch 35/100] Train Loss: 0.6974, Val Loss: 0.6916\n",
      "[Epoch 40/100] Train Loss: 0.7008, Val Loss: 0.6869\n",
      "[Epoch 45/100] Train Loss: 0.6972, Val Loss: 0.6854\n",
      "[Epoch 50/100] Train Loss: 0.6979, Val Loss: 0.6847\n",
      "[Epoch 55/100] Train Loss: 0.6985, Val Loss: 0.6818\n",
      "[Epoch 60/100] Train Loss: 0.6975, Val Loss: 0.6782\n",
      "[Epoch 65/100] Train Loss: 0.6971, Val Loss: 0.6808\n",
      "[Epoch 70/100] Train Loss: 0.6948, Val Loss: 0.6854\n",
      "[Epoch 75/100] Train Loss: 0.6943, Val Loss: 0.6870\n",
      "[Epoch 80/100] Train Loss: 0.6944, Val Loss: 0.6855\n",
      "[Epoch 85/100] Train Loss: 0.7042, Val Loss: 0.8122\n",
      "[Epoch 90/100] Train Loss: 0.6976, Val Loss: 0.6818\n",
      "[Epoch 95/100] Train Loss: 0.6968, Val Loss: 0.7216\n",
      "[Epoch 100/100] Train Loss: 0.7000, Val Loss: 0.6877\n",
      "Accuracy on Nonzero Predictions: 0.5952\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_gru_lr0.009_technical.png\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.7010, Val Loss: 0.6822\n",
      "[Epoch 10/100] Train Loss: 0.6962, Val Loss: 0.7358\n",
      "[Epoch 15/100] Train Loss: 0.6939, Val Loss: 0.6902\n",
      "[Epoch 20/100] Train Loss: 0.6972, Val Loss: 0.7011\n",
      "[Epoch 25/100] Train Loss: 0.6967, Val Loss: 0.6809\n",
      "[Epoch 30/100] Train Loss: 0.6957, Val Loss: 0.6819\n",
      "[Epoch 35/100] Train Loss: 0.6927, Val Loss: 0.6822\n",
      "[Epoch 40/100] Train Loss: 0.6908, Val Loss: 0.6798\n",
      "[Epoch 45/100] Train Loss: 0.6869, Val Loss: 0.6958\n",
      "[Epoch 50/100] Train Loss: 0.6900, Val Loss: 0.7060\n",
      "[Epoch 55/100] Train Loss: 0.6899, Val Loss: 0.7106\n",
      "[Epoch 60/100] Train Loss: 0.6929, Val Loss: 0.6863\n",
      "[Epoch 65/100] Train Loss: 0.6866, Val Loss: 0.7349\n",
      "[Epoch 70/100] Train Loss: 0.6851, Val Loss: 0.7831\n",
      "[Epoch 75/100] Train Loss: 0.6836, Val Loss: 0.7545\n",
      "[Epoch 80/100] Train Loss: 0.6798, Val Loss: 0.6972\n",
      "[Epoch 85/100] Train Loss: 0.6860, Val Loss: 0.7474\n",
      "[Epoch 90/100] Train Loss: 0.6838, Val Loss: 0.6989\n",
      "[Epoch 95/100] Train Loss: 0.6782, Val Loss: 0.7903\n",
      "[Epoch 100/100] Train Loss: 0.6779, Val Loss: 0.7912\n",
      "Accuracy on Nonzero Predictions: 0.3810\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_gru_lr0.01_technical.png\n",
      "Training AAPL | LR: 0.011 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6798, Val Loss: 0.8328\n",
      "[Epoch 10/100] Train Loss: 0.6837, Val Loss: 0.7953\n",
      "[Epoch 15/100] Train Loss: 0.6767, Val Loss: 0.9537\n",
      "[Epoch 20/100] Train Loss: 0.6822, Val Loss: 0.7985\n",
      "[Epoch 25/100] Train Loss: 0.6800, Val Loss: 0.7597\n",
      "[Epoch 30/100] Train Loss: 0.6779, Val Loss: 0.8072\n",
      "[Epoch 35/100] Train Loss: 0.6766, Val Loss: 0.7819\n",
      "[Epoch 40/100] Train Loss: 0.6867, Val Loss: 0.6928\n",
      "[Epoch 45/100] Train Loss: 0.6765, Val Loss: 0.7113\n",
      "[Epoch 50/100] Train Loss: 0.6744, Val Loss: 0.6992\n",
      "[Epoch 55/100] Train Loss: 0.6855, Val Loss: 0.7106\n",
      "[Epoch 60/100] Train Loss: 0.6818, Val Loss: 0.7620\n",
      "[Epoch 65/100] Train Loss: 0.6807, Val Loss: 0.7406\n",
      "[Epoch 70/100] Train Loss: 0.6823, Val Loss: 0.7030\n",
      "[Epoch 75/100] Train Loss: 0.6875, Val Loss: 0.7150\n",
      "[Epoch 80/100] Train Loss: 0.6890, Val Loss: 0.7207\n",
      "[Epoch 85/100] Train Loss: 0.6828, Val Loss: 0.7884\n",
      "[Epoch 90/100] Train Loss: 0.6845, Val Loss: 0.7425\n",
      "[Epoch 95/100] Train Loss: 0.6830, Val Loss: 0.7243\n",
      "[Epoch 100/100] Train Loss: 0.6877, Val Loss: 0.6885\n",
      "Accuracy on Nonzero Predictions: 0.6111\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_gru_lr0.011_technical.png\n",
      "[0.5952380952380952, 0.38095238095238093, 0.6111111111111112]\n",
      "[0.444777378611543, -2.496953515240042, 0.850185730436737]\n",
      "clean, gru, options\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/horizontal_structure/clean/options/AAPL/10y_5_data.pkl\n",
      "Training AAPL | LR: 0.009 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.6893, Val Loss: 0.6800\n",
      "[Epoch 10/100] Train Loss: 0.6887, Val Loss: 0.6738\n",
      "[Epoch 15/100] Train Loss: 0.6888, Val Loss: 0.6657\n",
      "[Epoch 20/100] Train Loss: 0.6790, Val Loss: 0.6652\n",
      "[Epoch 25/100] Train Loss: 0.6711, Val Loss: 0.6721\n",
      "[Epoch 30/100] Train Loss: 0.6216, Val Loss: 0.6732\n",
      "[Epoch 35/100] Train Loss: 0.6087, Val Loss: 0.7733\n",
      "[Epoch 40/100] Train Loss: 0.5390, Val Loss: 0.8460\n",
      "[Epoch 45/100] Train Loss: 0.5597, Val Loss: 0.8223\n",
      "[Epoch 50/100] Train Loss: 0.5003, Val Loss: 0.8910\n",
      "[Epoch 55/100] Train Loss: 0.4971, Val Loss: 0.9612\n",
      "[Epoch 60/100] Train Loss: 0.4353, Val Loss: 1.1287\n",
      "[Epoch 65/100] Train Loss: 0.4211, Val Loss: 1.1246\n",
      "[Epoch 70/100] Train Loss: 0.3936, Val Loss: 1.1993\n",
      "[Epoch 75/100] Train Loss: 0.3643, Val Loss: 1.4147\n",
      "[Epoch 80/100] Train Loss: 0.3912, Val Loss: 1.3051\n",
      "[Epoch 85/100] Train Loss: 0.3673, Val Loss: 1.3972\n",
      "[Epoch 90/100] Train Loss: 0.3366, Val Loss: 1.4257\n",
      "[Epoch 95/100] Train Loss: 0.3072, Val Loss: 1.4889\n",
      "[Epoch 100/100] Train Loss: 0.3144, Val Loss: 1.3209\n",
      "Accuracy on Nonzero Predictions: 0.5725\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_gru_lr0.009_options.png\n",
      "Training AAPL | LR: 0.01 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.3571, Val Loss: 1.5588\n",
      "[Epoch 10/100] Train Loss: 0.3326, Val Loss: 1.4469\n",
      "[Epoch 15/100] Train Loss: 0.3186, Val Loss: 1.3992\n",
      "[Epoch 20/100] Train Loss: 0.2958, Val Loss: 1.5419\n",
      "[Epoch 25/100] Train Loss: 0.3248, Val Loss: 1.6507\n",
      "[Epoch 30/100] Train Loss: 0.3389, Val Loss: 1.4447\n",
      "[Epoch 35/100] Train Loss: 0.3367, Val Loss: 1.4528\n",
      "[Epoch 40/100] Train Loss: 0.3428, Val Loss: 1.4476\n",
      "[Epoch 45/100] Train Loss: 0.3173, Val Loss: 1.4482\n",
      "[Epoch 50/100] Train Loss: 0.3711, Val Loss: 1.1746\n",
      "[Epoch 55/100] Train Loss: 0.3381, Val Loss: 1.3270\n",
      "[Epoch 60/100] Train Loss: 0.3333, Val Loss: 1.7563\n",
      "[Epoch 65/100] Train Loss: 0.3421, Val Loss: 1.4816\n",
      "[Epoch 70/100] Train Loss: 0.3514, Val Loss: 1.2257\n",
      "[Epoch 75/100] Train Loss: 0.3501, Val Loss: 1.4711\n",
      "[Epoch 80/100] Train Loss: 0.3955, Val Loss: 1.2901\n",
      "[Epoch 85/100] Train Loss: 0.3449, Val Loss: 1.5490\n",
      "[Epoch 90/100] Train Loss: 0.3422, Val Loss: 1.5665\n",
      "[Epoch 95/100] Train Loss: 0.3468, Val Loss: 2.1621\n",
      "[Epoch 100/100] Train Loss: 0.3444, Val Loss: 1.6557\n",
      "Accuracy on Nonzero Predictions: 0.4504\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_gru_lr0.01_options.png\n",
      "Training AAPL | LR: 0.011 | Epochs: 100 | Batch: 32 | Prediction Threshold: 0.5\n",
      "[Epoch 5/100] Train Loss: 0.3962, Val Loss: 1.6294\n",
      "[Epoch 10/100] Train Loss: 0.3736, Val Loss: 1.1147\n",
      "[Epoch 15/100] Train Loss: 0.3653, Val Loss: 1.1330\n",
      "[Epoch 20/100] Train Loss: 0.4051, Val Loss: 1.1555\n",
      "[Epoch 25/100] Train Loss: 0.4007, Val Loss: 0.8875\n",
      "[Epoch 30/100] Train Loss: 0.3871, Val Loss: 1.0765\n",
      "[Epoch 35/100] Train Loss: 0.3941, Val Loss: 1.2205\n",
      "[Epoch 40/100] Train Loss: 0.3869, Val Loss: 1.3602\n",
      "[Epoch 45/100] Train Loss: 0.4087, Val Loss: 0.9676\n",
      "[Epoch 50/100] Train Loss: 0.4267, Val Loss: 1.1603\n",
      "[Epoch 55/100] Train Loss: 0.4521, Val Loss: 1.1648\n",
      "[Epoch 60/100] Train Loss: 0.4332, Val Loss: 1.0896\n",
      "[Epoch 65/100] Train Loss: 0.4482, Val Loss: 1.3514\n",
      "[Epoch 70/100] Train Loss: 0.4619, Val Loss: 1.0140\n",
      "[Epoch 75/100] Train Loss: 0.4036, Val Loss: 1.2300\n",
      "[Epoch 80/100] Train Loss: 0.4445, Val Loss: 1.1720\n",
      "[Epoch 85/100] Train Loss: 0.4043, Val Loss: 1.1308\n",
      "[Epoch 90/100] Train Loss: 0.4871, Val Loss: 1.2647\n",
      "[Epoch 95/100] Train Loss: 0.4724, Val Loss: 0.9108\n",
      "[Epoch 100/100] Train Loss: 0.4216, Val Loss: 1.2584\n",
      "Accuracy on Nonzero Predictions: 0.4962\n",
      "Loss curves saved to: /home/jupyter-tfg2425paula/prediction_project_v3/03_plots/learning_rates_processing/AAPL_clean_gru_lr0.011_options.png\n",
      "[0.5725190839694656, 0.45038167938931295, 0.4961832061068702]\n",
      "[-54.91203526580593, -10.968435516218165, 16.774954151876162]\n"
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "stock = \"AAPL\"\n",
    "period = \"10y\"\n",
    "possible_train_size = 95\n",
    "window_size = 5\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "\n",
    "prediction_threshold = 0.5\n",
    "\n",
    "output_folder = os.path.join(results_dir, f\"inidividual_trials\") \n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "results_csv_path = os.path.join(output_folder, f\"01_{stock}_proc_model_type.csv\")\n",
    "processing_types = [\"pca\", \"clean\"]\n",
    "types_securities = [\"single_name\", \"technical\", \"options\"]\n",
    "\n",
    "\n",
    "learning_rates = [0.009, 0.01, 0.011]\n",
    "\n",
    "results_list = []\n",
    "for processing in processing_types:\n",
    "    for model_type in model_types:\n",
    "        for security_type in types_securities:\n",
    "            if security_type == \"single_name\":\n",
    "                modified_processing = \"clean\"\n",
    "            else:\n",
    "                modified_processing = processing\n",
    "                \n",
    "            initial_data_dir = os.path.join(project_dir, f\"00_data/{modified_processing}\") \n",
    "            \n",
    "            test_accuracy_list = []\n",
    "            pct_decrease_list = []\n",
    "            \n",
    "            # Load original data (info only)\n",
    "            filename = f\"{security_type}/{stock}/{period}_data.csv\"\n",
    "            original_input_filepath = os.path.join(initial_data_dir, filename)\n",
    "            original_data = pd.read_csv(original_input_filepath)\n",
    "\n",
    "            # Iterate over window sizes\n",
    "            print(f\"{modified_processing}, {model_type}, {security_type}\")\n",
    "\n",
    "            # Load data using the 'processing' variable in path\n",
    "            pkl_filename = f\"{modified_processing}/{security_type}/{stock}/{period}_{window_size}_data.pkl\"\n",
    "            input_filepath = os.path.join(horizontal_data_dir, pkl_filename)\n",
    "            print(input_filepath)\n",
    "            input_df = pd.read_pickle(input_filepath)\n",
    "\n",
    "            X_resampled, y_resampled = reshape_remove_characters(input_df)\n",
    "\n",
    "            input_size = X_resampled.shape[2]\n",
    "            train_size = int(X_resampled.shape[0] * possible_train_size / 100)\n",
    "            test_size = X_resampled.shape[0] - train_size\n",
    "\n",
    "            # Generate model\n",
    "            if model_type == \"gru\":\n",
    "                model = GRU3DClassifier(input_size, hidden_size, output_size, num_layers, dropout)\n",
    "            elif model_type == \"lstm\":\n",
    "                model = StockPriceLSTM(input_size, hidden_size, output_size)\n",
    "\n",
    "            model = model.to(device)\n",
    "            \n",
    "            for learning_rate in learning_rates:\n",
    "                optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                print(f\"Training {stock} | LR: {learning_rate} | Epochs: {num_epochs} \"\n",
    "                      f\"| Batch: {batch_size} | Prediction Threshold: {prediction_threshold}\")\n",
    "\n",
    "                result = evaluate_rolling_unchanged_model_threshold(\n",
    "                    model=model,\n",
    "                    X=X_resampled,\n",
    "                    y=y_resampled,\n",
    "                    criterion=criterion,\n",
    "                    optimizer=optimizer,\n",
    "                    device=device,\n",
    "                    train_size=train_size,\n",
    "                    batch_size=batch_size,\n",
    "                    num_epochs=num_epochs,\n",
    "                    lower_threshold=0.5,\n",
    "                    plots_dir=plots_dir,                # folder where plots are saved\n",
    "                    plot_filename=f\"learning_rates_processing/AAPL_{modified_processing}_{model_type}_lr{learning_rate}_{security_type}.png\" # optional custom filename\n",
    "                )    \n",
    "\n",
    "                rolling_predictions = result[\"rolling_predictions\"]\n",
    "                rolling_targets = result[\"rolling_targets\"]\n",
    "                test_accuracy = result[\"accuracy_nonzero\"]\n",
    "                loss_decrease_percentage = result[\"loss_decrease_percentage\"]\n",
    "                nonzero_preds = np.count_nonzero(rolling_predictions)\n",
    "                \n",
    "                test_accuracy_list.append(test_accuracy)\n",
    "                pct_decrease_list.append(loss_decrease_percentage)\n",
    "\n",
    "            print(test_accuracy_list)\n",
    "            print(pct_decrease_list)\n",
    "            # 1) Create a record (dictionary) for this run\n",
    "            run_record = {\"STOCK\": stock,\n",
    "                \"DATA_TYPE\": security_type,\n",
    "                \"MODEL\": model_type.upper(),  # Convert to uppercase for consistency\n",
    "                \"PROCESSING\": modified_processing,\n",
    "                \"MEAN_ACCURACY\": np.mean(test_accuracy_list),\n",
    "                \"MAX_ACCURACY\": np.max(test_accuracy_list),\n",
    "                \"MIN_ACCURACY\": np.min(test_accuracy_list),\n",
    "                \"MEAN_TRAIN_PCT_DECREASE\": np.mean(test_accuracy_list)}\n",
    "\n",
    "            # 2) Append to list\n",
    "            results_list.append(run_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f719513e-7d1e-4fbd-8ce5-789f191fd420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STOCK</th>\n",
       "      <th>DATA_TYPE</th>\n",
       "      <th>MODEL</th>\n",
       "      <th>PROCESSING</th>\n",
       "      <th>MEAN_ACCURACY</th>\n",
       "      <th>MAX_ACCURACY</th>\n",
       "      <th>MIN_ACCURACY</th>\n",
       "      <th>MEAN_TRAIN_PCT_DECREASE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>single_name</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.569975</td>\n",
       "      <td>0.580153</td>\n",
       "      <td>0.564885</td>\n",
       "      <td>0.569975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>technical</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>pca</td>\n",
       "      <td>0.534392</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.534392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>options</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>pca</td>\n",
       "      <td>0.516539</td>\n",
       "      <td>0.557252</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.516539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>single_name</td>\n",
       "      <td>GRU</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.516539</td>\n",
       "      <td>0.526718</td>\n",
       "      <td>0.503817</td>\n",
       "      <td>0.516539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>technical</td>\n",
       "      <td>GRU</td>\n",
       "      <td>pca</td>\n",
       "      <td>0.513228</td>\n",
       "      <td>0.579365</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.513228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>options</td>\n",
       "      <td>GRU</td>\n",
       "      <td>pca</td>\n",
       "      <td>0.577608</td>\n",
       "      <td>0.595420</td>\n",
       "      <td>0.549618</td>\n",
       "      <td>0.577608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>single_name</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.463104</td>\n",
       "      <td>0.511450</td>\n",
       "      <td>0.389313</td>\n",
       "      <td>0.463104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>technical</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.547619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>options</td>\n",
       "      <td>LSTM</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.491094</td>\n",
       "      <td>0.534351</td>\n",
       "      <td>0.427481</td>\n",
       "      <td>0.491094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>single_name</td>\n",
       "      <td>GRU</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.511450</td>\n",
       "      <td>0.549618</td>\n",
       "      <td>0.488550</td>\n",
       "      <td>0.511450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>technical</td>\n",
       "      <td>GRU</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.529101</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.529101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>options</td>\n",
       "      <td>GRU</td>\n",
       "      <td>clean</td>\n",
       "      <td>0.506361</td>\n",
       "      <td>0.572519</td>\n",
       "      <td>0.450382</td>\n",
       "      <td>0.506361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STOCK    DATA_TYPE MODEL PROCESSING  MEAN_ACCURACY  MAX_ACCURACY  \\\n",
       "0   AAPL  single_name  LSTM      clean       0.569975      0.580153   \n",
       "1   AAPL    technical  LSTM        pca       0.534392      0.547619   \n",
       "2   AAPL      options  LSTM        pca       0.516539      0.557252   \n",
       "3   AAPL  single_name   GRU      clean       0.516539      0.526718   \n",
       "4   AAPL    technical   GRU        pca       0.513228      0.579365   \n",
       "5   AAPL      options   GRU        pca       0.577608      0.595420   \n",
       "6   AAPL  single_name  LSTM      clean       0.463104      0.511450   \n",
       "7   AAPL    technical  LSTM      clean       0.547619      0.587302   \n",
       "8   AAPL      options  LSTM      clean       0.491094      0.534351   \n",
       "9   AAPL  single_name   GRU      clean       0.511450      0.549618   \n",
       "10  AAPL    technical   GRU      clean       0.529101      0.611111   \n",
       "11  AAPL      options   GRU      clean       0.506361      0.572519   \n",
       "\n",
       "    MIN_ACCURACY  MEAN_TRAIN_PCT_DECREASE  \n",
       "0       0.564885                 0.569975  \n",
       "1       0.507937                 0.534392  \n",
       "2       0.488550                 0.516539  \n",
       "3       0.503817                 0.516539  \n",
       "4       0.428571                 0.513228  \n",
       "5       0.549618                 0.577608  \n",
       "6       0.389313                 0.463104  \n",
       "7       0.523810                 0.547619  \n",
       "8       0.427481                 0.491094  \n",
       "9       0.488550                 0.511450  \n",
       "10      0.380952                 0.529101  \n",
       "11      0.450382                 0.506361  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f66e150-dbc5-4435-80dc-1ec5f63c083f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae3ed3a-2b02-4e59-9050-410c808e6a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
