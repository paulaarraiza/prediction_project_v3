{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1d39fc-baf4-4625-a145-3f2bc29727d7",
   "metadata": {},
   "source": [
    "## **This code aims to clean all existing dfs**\n",
    "- Appropiate date format (if needed)\n",
    "- Creates Return column\n",
    "- Interpolate NA\n",
    "- Remove outliers\n",
    "- Generate target column\n",
    "- Create df's for each period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39edeafd-3de0-4eb4-aa19-f706926dcd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4629ea83-48ba-4585-a3d5-d0aa41d79b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = \"/home/jupyter-tfg2425paula/prediction_project_v3\"\n",
    "os.chdir(project_dir)\n",
    "\n",
    "raw_data_dir = os.path.join(project_dir, \"00_data/raw\")\n",
    "clean_data_dir = os.path.join(project_dir, \"00_data/clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab85158-4ca4-49c6-9cdc-bc2fc2b20b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def appropiate_date_format(df, date_col_name, date_format=\"%d/%m/%y\"):\n",
    "    \"\"\" Converts date column to appropiate format\n",
    "    \"\"\"\n",
    "    df[date_col_name] = pd.to_datetime(df[date_col_name], format=date_format)\n",
    "    return df\n",
    "\n",
    "def create_return_column(df, target_col_name):\n",
    "    \"\"\" Generates Return column\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[target_col_name] = pd.to_numeric(df[target_col_name], errors=\"coerce\")\n",
    "    df[\"Return\"] = df[target_col_name].pct_change(fill_method=\"pad\") * 100 \n",
    "    df = df.drop(columns = target_col_name)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def remove_na(df):\n",
    "    \"\"\"\n",
    "    Handles missing values in specified columns of a DataFrame using linear interpolation.\n",
    "    Removes rows with missing values if they are at the beginning or end.\n",
    "    \"\"\"\n",
    "    selected_cols = list(df.columns)\n",
    "    na_method = \"linear\"\n",
    "    df = df.iloc[1:].copy()\n",
    "    df = df.iloc[:-1].copy()\n",
    "    rows_with_na = df[df[selected_cols].isna().any(axis=1)]\n",
    "    for col in selected_cols:\n",
    "        df[col] = df[col].interpolate(na_method, limit_direction=\"both\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def replace_outliers_iqr(df, output_col):\n",
    "    \"\"\"\n",
    "    Replaces outliers in a DataFrame using the IQR method with interpolated or mean/median values.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        selected_col (str): The column to process.\n",
    "        threshold (float): The IQR threshold. Default is 1.5.\n",
    "        method (str): The method to replace outliers (\"interpolate\", \"mean\", \"median\"). Default is \"interpolate\".\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with outliers replaced.\n",
    "    \"\"\"\n",
    "    method=\"linear\"\n",
    "    threshold = 2.5\n",
    "    \n",
    "    col = output_col\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - threshold * IQR\n",
    "    upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "    outliers = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "    \n",
    "    extreme_outliers = df.loc[outliers, col]\n",
    "    num_outliers = len(extreme_outliers)\n",
    "    min_outlier = extreme_outliers.min() if not extreme_outliers.empty else None\n",
    "\n",
    "    print(f\"Number of outliers eliminated: {num_outliers}\")\n",
    "    print(f\"Minimum extreme outlier value: {min_outlier}\")\n",
    "    \n",
    "    df.loc[outliers, col] = np.nan\n",
    "    df[col] = df[col].interpolate(method, limit_direction=\"both\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_target_column(df, output_col):\n",
    "    df['Target'] = (df[output_col].shift(-1) > 0).astype(float)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def filter_by_period(df, years):\n",
    "    \"\"\"\n",
    "    Filters the dataframe rows based on the specified period.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing a 'Date' column.\n",
    "    years (list): List of time periods as strings, e.g., [\"15y\", \"10y\", \"5y\", \"2y\"].\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary of DataFrames filtered for each period.\n",
    "    \"\"\"\n",
    "    # Ensure 'Date' column is in datetime format\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "    # Find the most recent date in the dataset\n",
    "    max_date = df[\"Date\"].max()\n",
    "\n",
    "    # Dictionary to store filtered DataFrames\n",
    "    filtered_dfs = {}\n",
    "\n",
    "    # Iterate over the given periods\n",
    "    for period in years:\n",
    "        print(period)\n",
    "        num_years = int(period[:-1])  # Extract numeric part\n",
    "        cutoff_date = max_date - pd.DateOffset(years=num_years)  # Compute cutoff date\n",
    "\n",
    "        # Filter DataFrame\n",
    "        filtered_df = df[df[\"Date\"] >= cutoff_date]\n",
    "\n",
    "        filtered_df = filtered_df.reset_index(drop=True)\n",
    "        \n",
    "        # Store in dictionary\n",
    "        filtered_dfs[period] = filtered_df\n",
    "\n",
    "    return filtered_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4650923d-d11f-495a-8ba2-414723a86185",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "technical/SPX_technical.csv\n",
      "Number of outliers eliminated: 94\n",
      "Minimum extreme outlier value: -11.984055240393443\n",
      "2y\n",
      "5y\n",
      "10y\n",
      "15y\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/clean/technical/SPX/2y_data.csv\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/clean/technical/SPX/5y_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53491/289240904.py:12: FutureWarning: The 'fill_method' keyword being not None and the 'limit' keyword in Series.pct_change are deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df[\"Return\"] = df[target_col_name].pct_change(fill_method=\"pad\") * 100\n",
      "/tmp/ipykernel_53491/289240904.py:28: FutureWarning: Series.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  df[col] = df[col].interpolate(na_method, limit_direction=\"both\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/clean/technical/SPX/10y_data.csv\n",
      "/home/jupyter-tfg2425paula/prediction_project_v3/00_data/clean/technical/SPX/15y_data.csv\n"
     ]
    }
   ],
   "source": [
    "types_securities = [\"technical\"]\n",
    "stocks = ['SPX']\n",
    "years = [\"2y\", \"5y\", \"10y\", \"15y\"]\n",
    "\n",
    "\n",
    "price_column = {\"single_name\": 0, \n",
    "                \"options\": 1,\n",
    "                \"technical\": 0\n",
    "}\n",
    "\n",
    "file_names = {\"single_name\": \"_Close.csv\", \n",
    "                \"options\": \"_options.csv\",\n",
    "                \"technical\": \"_technical.csv\"\n",
    "}\n",
    "\n",
    "seps = { \"single_name\": \";\", \n",
    "                \"options\": \",\",\n",
    "                \"technical\": \",\"\n",
    "}\n",
    "decs = { \"single_name\": \",\", \n",
    "                \"options\": \".\",\n",
    "                \"technical\": \".\"\n",
    "}\n",
    "\n",
    "for security_type in types_securities:\n",
    "    for stock in stocks:\n",
    "        output_folder = os.path.join(clean_data_dir, f\"{security_type}/{stock}\")\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        intial_df = pd.read_csv(os.path.join(raw_data_dir, f\"{security_type}/{stock}{file_names[security_type]}\"), \n",
    "                                sep=seps[security_type], decimal=decs[security_type])\n",
    "        print(f\"{security_type}/{stock}{file_names[security_type]}\")\n",
    "        \n",
    "        if security_type == \"single_name\":\n",
    "            intial_df = appropiate_date_format(intial_df, \"Date\", date_format=\"%d/%m/%y\")\n",
    "        df = create_return_column(intial_df, f\"{price_column[security_type]*str(stock+'_')}\"+\"Close\")\n",
    "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        df = remove_na(df)        \n",
    "        df = replace_outliers_iqr(df, \"Return\")\n",
    "        df = generate_target_column(df, \"Return\")\n",
    "\n",
    "        filtered_results = filter_by_period(df, years)\n",
    "        \n",
    "        for period, df_filtered in filtered_results.items():\n",
    "            print(os.path.join(output_folder, f\"{period}_data.csv\"))\n",
    "            df_filtered.to_csv(os.path.join(output_folder, f\"{period}_data.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fea1e-e7e6-4f49-8f67-680075535efe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
